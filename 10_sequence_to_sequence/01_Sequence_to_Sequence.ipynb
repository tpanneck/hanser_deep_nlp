{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0401eadf",
   "metadata": {},
   "source": [
    "# 10.3.1 Ein einfaches Encoder-Decoder-Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6829c730",
   "metadata": {},
   "source": [
    "### 01 - Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d8773c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['jeddes', 'verlchivdene', 'zwnächst', 'gang', 'aßso'],\n",
       " ['jedes', 'verschiedene', 'zunächst', 'ging', 'also'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = r'..\\Data'\n",
    "\n",
    "### 1) Misspelling-Daten laden\n",
    "df_train = pd.read_csv(join(path, 'train_spelling.csv'))\n",
    "df_test = pd.read_csv(join(path, 'test_spelling.csv'))\n",
    "df = df_train.append(df_test)\n",
    "df.head()\n",
    "len(df), len(df_train), len(df_test)\n",
    "\n",
    "X, y = df['misspelling'].values.tolist(), df['word'].values.tolist()\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b4a67a",
   "metadata": {},
   "source": [
    "### 02 - Zeitversetzte Eingabe produzieren (Für Teacher Force Verfahren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf0f1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['jeddes', 'verlchivdene', 'zwnächst', 'gang', 'aßso'],\n",
       " ['\\tjedes', '\\tverschiedene', '\\tzunächst', '\\tging', '\\talso'],\n",
       " ['jedes', 'verschiedene', 'zunächst', 'ging', 'also'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def insert_start_sign(words: list, start='\\t'):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new = start + word\n",
    "        new_words.append(new)\n",
    "    return new_words\n",
    "\n",
    "X1 = X\n",
    "X2 = insert_start_sign(y)\n",
    "X1[:5], X2[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6364c1",
   "metadata": {},
   "source": [
    "### 03 - One Hot Encodierung der Sequenzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a308136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3) One-Hot-Encodierung\n",
    "def max_char_length(words: list):\n",
    "    char_len = 0\n",
    "    for word in words:\n",
    "        if len(word) > char_len:\n",
    "            char_len = len(word)\n",
    "    return char_len\n",
    "\n",
    "def words_to_char_matrix( words: list, \n",
    "                          char_dic: dict, \n",
    "                          max_len: int,\n",
    "                          end_sign='\\n'):\n",
    "    x = np.zeros(shape=(len(words), max_len, len(char_dic)), dtype='int32')\n",
    "    for idx, word in enumerate(words):\n",
    "        for i, char in enumerate(word):\n",
    "            x[idx, i, char_dic[char]] = 1\n",
    "        for i in range(len(word), max_len):\n",
    "            x[idx, i, char_dic[end_sign]] = 1\n",
    "    return x\n",
    "\n",
    "def char_matrix_to_words( matrix: np.array,\n",
    "                          char_dic: dict):\n",
    "    char_dic_rev = dict([ (idx, char) for char, idx in char_dic.items()])\n",
    "    char_list = []\n",
    "    for seq in matrix:\n",
    "        y_idx = np.argmax(seq)\n",
    "        y_char = char_dic_rev[y_idx]\n",
    "        char_list.append(y_char)\n",
    "    return char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc0251",
   "metadata": {},
   "source": [
    "#### Funktionen aufrufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03bf06c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15921, 15, 33), (15921, 15, 33), (15921, 15, 33))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dic = dict([(char, i) for i, char \n",
    "                in enumerate(list('.abcdefghijklmnopqrstuvwxyzäöüß\\n\\t')) ])\n",
    "len_X1 = max_char_length(X1)\n",
    "len_X2 = max_char_length(X2)\n",
    "len_y = max_char_length(y)\n",
    "len_X1, len_X2, len_y\n",
    "\n",
    "\n",
    "X1_ = words_to_char_matrix(X1, char_dic, len_X1)\n",
    "X2_ = words_to_char_matrix(X2, char_dic, len_X2)\n",
    "y_ = words_to_char_matrix(y, char_dic, len_X2)\n",
    "X1_.shape, X2_.shape, y_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452ff7d",
   "metadata": {},
   "source": [
    "#### Test (Rückübersetzung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5398afc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['j',\n",
       " 'e',\n",
       " 'd',\n",
       " 'e',\n",
       " 's',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_matrix_to_words(X1_[0], char_dic)\n",
    "char_matrix_to_words(X2_[0], char_dic)\n",
    "char_matrix_to_words(y_[0], char_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42892fb",
   "metadata": {},
   "source": [
    "### 04 - Sequence-to-Sequence Trainingsmodell aufsetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5864ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_in (InputLayer)         [(None, None, 33)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_in (InputLayer)         [(None, None, 33)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru (GRU)               (None, 100)          40500       encoder_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, None, 100),  40500       decoder_in[0][0]                 \n",
      "                                                                 encoder_gru[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 33)     3333        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 84,333\n",
      "Trainable params: 84,333\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (GRU, Input, \n",
    "                                     Dense, TimeDistributed)\n",
    "\n",
    "units= 100\n",
    "encoder_in = Input(shape=(None, len(char_dic)), name='encoder_in')\n",
    "encoder_state = GRU( units=units, \n",
    "                     name='encoder_gru')(encoder_in)\n",
    "\n",
    "decoder_in = Input(shape=(None, len(char_dic)), name='decoder_in')\n",
    "decoder_gru = GRU( units=units, return_sequences=True, return_state=True, \n",
    "           name='decoder_gru')\n",
    "gru_out, gru_state = decoder_gru(decoder_in, initial_state=encoder_state)\n",
    "dense = Dense(units=len(char_dic), activation='softmax')\n",
    "decoder_out = TimeDistributed(dense, name='time_distributed')(gru_out)\n",
    "\n",
    "model = Model([encoder_in, decoder_in], decoder_out )\n",
    "model.compile( loss='categorical_crossentropy', optimizer='adam', \n",
    "               metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f36cc4",
   "metadata": {},
   "source": [
    "### 05 - Training des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "916a1c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "396/398 [============================>.] - ETA: 0s - loss: 1.3276 - accuracy: 0.6390WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "398/398 [==============================] - 7s 18ms/step - loss: 1.3263 - accuracy: 0.6393 - val_loss: 1.0248 - val_accuracy: 0.6893\n",
      "Epoch 2/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.9377 - accuracy: 0.7167 - val_loss: 0.8592 - val_accuracy: 0.7380\n",
      "Epoch 3/50\n",
      "398/398 [==============================] - 6s 15ms/step - loss: 0.7827 - accuracy: 0.7631 - val_loss: 0.6979 - val_accuracy: 0.7880\n",
      "Epoch 4/50\n",
      "398/398 [==============================] - 6s 15ms/step - loss: 0.6364 - accuracy: 0.8096 - val_loss: 0.5729 - val_accuracy: 0.8315\n",
      "Epoch 5/50\n",
      "398/398 [==============================] - 6s 15ms/step - loss: 0.5231 - accuracy: 0.8453 - val_loss: 0.4821 - val_accuracy: 0.8545\n",
      "Epoch 6/50\n",
      "398/398 [==============================] - 7s 17ms/step - loss: 0.4369 - accuracy: 0.8674 - val_loss: 0.4002 - val_accuracy: 0.8785\n",
      "Epoch 7/50\n",
      "398/398 [==============================] - 7s 17ms/step - loss: 0.3582 - accuracy: 0.8923 - val_loss: 0.3246 - val_accuracy: 0.9046\n",
      "Epoch 8/50\n",
      "398/398 [==============================] - 7s 17ms/step - loss: 0.2879 - accuracy: 0.9155 - val_loss: 0.2745 - val_accuracy: 0.9192\n",
      "Epoch 9/50\n",
      "398/398 [==============================] - 7s 17ms/step - loss: 0.2365 - accuracy: 0.9314 - val_loss: 0.2193 - val_accuracy: 0.9382\n",
      "Epoch 10/50\n",
      "398/398 [==============================] - 7s 17ms/step - loss: 0.1968 - accuracy: 0.9446 - val_loss: 0.1889 - val_accuracy: 0.9470\n",
      "Epoch 11/50\n",
      "398/398 [==============================] - 7s 16ms/step - loss: 0.1693 - accuracy: 0.9525 - val_loss: 0.1677 - val_accuracy: 0.9528\n",
      "Epoch 12/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.1486 - accuracy: 0.9588 - val_loss: 0.1492 - val_accuracy: 0.9589\n",
      "Epoch 13/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.1323 - accuracy: 0.9635 - val_loss: 0.1340 - val_accuracy: 0.9629\n",
      "Epoch 14/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.1172 - accuracy: 0.9682 - val_loss: 0.1237 - val_accuracy: 0.9667\n",
      "Epoch 15/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.1069 - accuracy: 0.9710 - val_loss: 0.1143 - val_accuracy: 0.9684\n",
      "Epoch 16/50\n",
      "398/398 [==============================] - 7s 17ms/step - loss: 0.0950 - accuracy: 0.9746 - val_loss: 0.1165 - val_accuracy: 0.9672\n",
      "Epoch 17/50\n",
      "398/398 [==============================] - 7s 17ms/step - loss: 0.0868 - accuracy: 0.9764 - val_loss: 0.0929 - val_accuracy: 0.9752\n",
      "Epoch 18/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0802 - accuracy: 0.9783 - val_loss: 0.0894 - val_accuracy: 0.9761\n",
      "Epoch 19/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0722 - accuracy: 0.9807 - val_loss: 0.0881 - val_accuracy: 0.9761\n",
      "Epoch 20/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0667 - accuracy: 0.9820 - val_loss: 0.0789 - val_accuracy: 0.9785\n",
      "Epoch 21/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0618 - accuracy: 0.9833 - val_loss: 0.0759 - val_accuracy: 0.9794\n",
      "Epoch 22/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0567 - accuracy: 0.9846 - val_loss: 0.0711 - val_accuracy: 0.9801\n",
      "Epoch 23/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0539 - accuracy: 0.9852 - val_loss: 0.0677 - val_accuracy: 0.9816\n",
      "Epoch 24/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0488 - accuracy: 0.9868 - val_loss: 0.0650 - val_accuracy: 0.9828\n",
      "Epoch 25/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0468 - accuracy: 0.9870 - val_loss: 0.0664 - val_accuracy: 0.9816\n",
      "Epoch 26/50\n",
      "398/398 [==============================] - 7s 18ms/step - loss: 0.0417 - accuracy: 0.9889 - val_loss: 0.0619 - val_accuracy: 0.9828\n",
      "Epoch 27/50\n",
      "398/398 [==============================] - 7s 17ms/step - loss: 0.0387 - accuracy: 0.9893 - val_loss: 0.0582 - val_accuracy: 0.9837\n",
      "Epoch 28/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0354 - accuracy: 0.9904 - val_loss: 0.0589 - val_accuracy: 0.9834\n",
      "Epoch 29/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0343 - accuracy: 0.9906 - val_loss: 0.0535 - val_accuracy: 0.9851\n",
      "Epoch 30/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 0.0584 - val_accuracy: 0.9838\n",
      "Epoch 31/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0289 - accuracy: 0.9922 - val_loss: 0.0515 - val_accuracy: 0.9853\n",
      "Epoch 32/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.0524 - val_accuracy: 0.9856\n",
      "Epoch 33/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0260 - accuracy: 0.9928 - val_loss: 0.0471 - val_accuracy: 0.9869\n",
      "Epoch 34/50\n",
      "398/398 [==============================] - 6s 16ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0520 - val_accuracy: 0.9857\n",
      "Epoch 35/50\n",
      "398/398 [==============================] - 7s 17ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 0.0481 - val_accuracy: 0.9862\n",
      "Epoch 36/50\n",
      "398/398 [==============================] - 7s 17ms/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 0.0483 - val_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "stopping = EarlyStopping( monitor='val_loss', \n",
    "                            patience=3,\n",
    "                            restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint( filepath='SeqToSeq_spelling.h5',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "history = model.fit( [X1_, X2_], y_, \n",
    "                     epochs=50, \n",
    "                     batch_size=32,\n",
    "                     validation_split=.2,\n",
    "                     callbacks=[stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9ea02",
   "metadata": {},
   "source": [
    "#### Angelerntes Modell laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6fbac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_in (InputLayer)         [(None, None, 33)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_in (InputLayer)         [(None, None, 33)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru (GRU)               (None, 100)          40500       encoder_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, None, 100),  40500       decoder_in[0][0]                 \n",
      "                                                                 encoder_gru[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 33)     3333        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 84,333\n",
      "Trainable params: 84,333\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model( 'SeqToSeq_spelling.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237b222",
   "metadata": {},
   "source": [
    "### 06 - Inferenzmodell aufsetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f3db7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_in (InputLayer)      [(None, None, 33)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_gru (GRU)            (None, 100)               40500     \n",
      "=================================================================\n",
      "Total params: 40,500\n",
      "Trainable params: 40,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_in (InputLayer)         [(None, None, 33)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_state_in (InputLayer)   [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, None, 100),  40500       decoder_in[0][0]                 \n",
      "                                                                 decoder_state_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 33)     3333        decoder_gru[2][0]                \n",
      "==================================================================================================\n",
      "Total params: 43,833\n",
      "Trainable params: 43,833\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1) Encoder Modell zusammenstecken\n",
    "encoder_in = model.get_layer('encoder_in').input\n",
    "encoder_state = model.get_layer('encoder_gru').output\n",
    "\n",
    "encoder_model = Model(encoder_in, encoder_state)\n",
    "\n",
    "### 2) Decoder-Modell zusammensetzen\n",
    "units = 100\n",
    "decoder_state_input = Input(shape=(units,), name='decoder_state_in')\n",
    "decoder_inputs = model.get_layer('decoder_in').input\n",
    "decoder_gru = model.get_layer('decoder_gru')\n",
    "decoder_time = model.get_layer('time_distributed')\n",
    "\n",
    "decoder_outputs, decoder_state = decoder_gru(\n",
    "    decoder_inputs, initial_state=decoder_state_input)\n",
    "decoder_outputs = decoder_time(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs, decoder_state_input],\n",
    "    [decoder_outputs, decoder_state])\n",
    "\n",
    "encoder_model.summary(), decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e19eb9",
   "metadata": {},
   "source": [
    "#### Beispielschätzungen durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca38c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def predict_correct(misspelled, encoder, decoder, \n",
    "                    char_dict: dict, len_seq=15):\n",
    "\n",
    "    input_seq = words_to_char_matrix([misspelled], char_dict, len_seq)\n",
    "    index_char_dict = dict([(i, char) for char, i in char_dict.items()])\n",
    "\n",
    "    state = encoder.predict(input_seq)\n",
    "    decoder_seq = np.zeros(shape=(1, 1, len(char_dict)), dtype='int32')\n",
    "    decoder_seq[0, 0, char_dict['\\t']] = 1\n",
    "    \n",
    "    decoded_word = ''\n",
    "    for i in range(len_seq):\n",
    "        output_char, dec_state = decoder.predict(\n",
    "                                 [decoder_seq] + [state])\n",
    "\n",
    "        char_index = np.argmax(output_char[0, 0])\n",
    "        char = index_char_dict[char_index]\n",
    "        \n",
    "        if char == '\\n':\n",
    "            return decoded_word\n",
    "\n",
    "        decoded_word += char\n",
    "        decoder_seq = np.zeros(shape=(1, 1, len(char_dict)), dtype='int32')\n",
    "        decoder_seq[0, 0, char_index] = 1\n",
    "\n",
    "        state = dec_state\n",
    "\n",
    "    return decoded_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6799e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vielleicht'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misspelled = 'vielheiicht'\n",
    "predict_correct(misspelled, encoder_model, decoder_model, char_dic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
