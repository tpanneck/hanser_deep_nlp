{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9ecf44",
   "metadata": {},
   "source": [
    "# Kapitel 10.3.2\t\n",
    "## Encoder-Decoder-Modelle mit Attention-Mechanismus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f468131",
   "metadata": {},
   "source": [
    "### 01 - Laden relevanter Klassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60324896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Laden relevanter Klassen\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, Embedding, GRU, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "### Eigene Klassen (liegen im aktuellen Verzeichnis)\n",
    "from attention_layer import AttentionLayer\n",
    "import load_translation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09d679",
   "metadata": {},
   "source": [
    "### 02 - Trainingsdaten laden\n",
    "Unter Verwendung der Funktion *load_data* aus der Datei *load_translation_data.py* - liegt im aktuellen Verzeichnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94bc132f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Geh.', 'Hallo!', 'Grüß Gott!', 'Lauf!', 'Lauf!'] ['<start> Go.', '<start> Hi.', '<start> Hi.', '<start> Run!', '<start> Run.'] ['Go.', 'Hi.', 'Hi.', 'Run!', 'Run.']\n",
      "[[609], [1742], [4275, 1540], [4644], [4644]] [[1, 44], [1, 2152], [1, 2152], [1, 465], [1, 465]] [[44], [2152], [2152], [465], [465]]\n",
      "max length german 19\n",
      "max length english 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((220672, 19),\n",
       " (220672, 25),\n",
       " (220672, 25),\n",
       " <keras_preprocessing.text.Tokenizer at 0x2202b85c048>,\n",
       " <keras_preprocessing.text.Tokenizer at 0x2202b85c108>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_pad, X2_pad, y_pad = load_translation_data.load_data(new_tokenizer=True)\n",
    "tok_de, tok_en = load_translation_data.load_tokenizer()\n",
    "X1_pad.shape, X2_pad.shape, y_pad.shape, tok_de, tok_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804be314",
   "metadata": {},
   "source": [
    "### 03 - Attention-Modell für Training anlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84589364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_model( seq_len_encoder: int, \n",
    "                         seq_len_decoder: int,\n",
    "                         num_words_encoder: int,\n",
    "                         num_words_decoder: int,\n",
    "                         vec_dim = 64, hidden_size = 64,\n",
    "                         ):\n",
    "\n",
    "    encoder_inputs = Input(shape=(seq_len_encoder,), name='encoder_inputs')\n",
    "    decoder_inputs = Input(shape=(seq_len_decoder,), name='decoder_inputs')\n",
    "    \n",
    "    # Encoder\n",
    "    encoder_emb = Embedding(input_dim=num_words_encoder+1, \n",
    "                            output_dim=vec_dim,\n",
    "                            name='encoder_emb')(encoder_inputs)\n",
    "    encoder_gru = Bidirectional(GRU(hidden_size, \n",
    "                                    return_sequences=True, \n",
    "                                    return_state=True), name='encoder_bi_gru')\n",
    "    encoder_out, encoder_ffw_state, encoder_bw_state = encoder_gru(encoder_emb)\n",
    "    \n",
    "    # Decoder \n",
    "    decoder_emb = Embedding(input_dim=num_words_decoder+1, \n",
    "                            output_dim=vec_dim, \n",
    "                            name='decoder_emb')(decoder_inputs)\n",
    "    decoder_gru = GRU(hidden_size*2, return_sequences=True, \n",
    "                return_state=True, name='decoder_gru')\n",
    "    encoder_state = Concatenate(axis=-1, \n",
    "                     name='concate_encoder')([encoder_ffw_state, encoder_bw_state])\n",
    "    decoder_out, decoder_state = decoder_gru(decoder_emb, \n",
    "                            initial_state=encoder_state)\n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer')\n",
    "    attn_out, attn_states = attn_layer([encoder_out, decoder_out])\n",
    "    \n",
    "    decoder_concat = Concatenate(axis=-1, name='concat_layer')([decoder_out, attn_out])\n",
    "    dense = Dense(num_words_decoder+1, activation='softmax', name='softmax_layer')\n",
    "    dense_time = TimeDistributed(dense, name='time_distributed_layer')\n",
    "    decoder_pred = dense_time(decoder_concat)\n",
    "    \n",
    "    # Model\n",
    "    model = Model( inputs=[encoder_inputs, decoder_inputs], \n",
    "                        outputs=decoder_pred)\n",
    "    model.compile( optimizer='adam', \n",
    "                        loss='sparse_categorical_crossentropy', \n",
    "                        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c307a1d0",
   "metadata": {},
   "source": [
    "#### Trainingsmodell laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46955104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 19)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_emb (Embedding)         (None, 19, 64)       2258368     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bi_gru (Bidirectional)  [(None, 19, 128), (N 49920       encoder_emb[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_emb (Embedding)         (None, 25, 64)       1042624     decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concate_encoder (Concatenate)   (None, 128)          0           encoder_bi_gru[0][1]             \n",
      "                                                                 encoder_bi_gru[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 25, 128), (N 74496       decoder_emb[0][0]                \n",
      "                                                                 concate_encoder[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, 25, 128), (N 32896       encoder_bi_gru[0][0]             \n",
      "                                                                 decoder_gru[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, 25, 256)      0           decoder_gru[0][0]                \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_layer (TimeDis (None, 25, 16291)    4186787     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,645,091\n",
      "Trainable params: 7,645,091\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_attention_model( seq_len_encoder=X1_pad.shape[1], \n",
    "                             seq_len_decoder=X2_pad.shape[1], \n",
    "                             num_words_encoder=len(tok_de.word_index), \n",
    "                             num_words_decoder=len(tok_en.word_index) )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb3a49",
   "metadata": {},
   "source": [
    "### 04 - Modell kompilieren, EarlyStopping und Checkpoints anlegen und Training starten\n",
    "Hinweis: Trainingsprozess ist hier nur angedeutet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3497ca5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  78/1552 [>.............................] - ETA: 1:16:01 - loss: 4.0137 - accuracy: 0.7610"
     ]
    }
   ],
   "source": [
    "model.compile( optimizer='adam', \n",
    "               loss='sparse_categorical_crossentropy', \n",
    "               metrics=['accuracy'])\n",
    "\n",
    "stopping = EarlyStopping( monitor='val_loss', \n",
    "                         patience=3,\n",
    "                         restore_best_weights=False)\n",
    "checkpoint = ModelCheckpoint( filepath='SeqToSeq_bi_attention.h5',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "history = model.fit([ X1_pad, X2_pad], y_pad, \n",
    "                        epochs=20, \n",
    "                        batch_size=128,\n",
    "                        validation_split=.1,\n",
    "                        callbacks=[stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b9096",
   "metadata": {},
   "source": [
    "#### Angelerntes Modell laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3cf3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model( 'SeqToSeq_bi_attention.h5',\n",
    "                    custom_objects={'AttentionLayer':AttentionLayer})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6aba5b",
   "metadata": {},
   "source": [
    "### 05 - Inferenzmodell aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814cae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_model(model, len_seq_encoder: int, hidden_size=64):\n",
    "    \n",
    "    batch_size = 1\n",
    "\n",
    "    # Encoder\n",
    "    encoder_in = model.get_layer('encoder_inputs').input\n",
    "    encoder_output, encoder_ffw_h, encoder_bw_h = \\\n",
    "                        model.get_layer('encoder_bi_gru').output\n",
    "    encoder_states = Concatenate( axis=-1, name='encoder_concat')(\n",
    "                                  [encoder_ffw_h, encoder_bw_h]) \n",
    "    encoder = Model( inputs=encoder_in, \n",
    "                     outputs=[encoder_output, encoder_states])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = Input(batch_shape=(batch_size, 1), \n",
    "                               name='decoder_word_inputs')\n",
    "    encoder_seq_states = Input(batch_shape=(batch_size, \n",
    "                                            len_seq_encoder, \n",
    "                                            hidden_size*2), name='encoder_seq_states')\n",
    "    decoder_init_state = Input(batch_shape=(batch_size, \n",
    "                                            hidden_size*2), name='decoder_init')\n",
    "\n",
    "    decoder_emb = model.get_layer('decoder_emb')\n",
    "    decoder_gru = model.get_layer('decoder_gru')\n",
    "    decoder_att = model.get_layer('attention_layer')\n",
    "    time_distributed = model.get_layer('time_distributed_layer')\n",
    "\n",
    "    decoder_emb = decoder_emb(decoder_inputs)\n",
    "    decoder_out, decoder_state = decoder_gru(decoder_emb, \n",
    "                                                     initial_state=decoder_init_state)\n",
    "    attn_out, attn_states = decoder_att([ encoder_seq_states, \n",
    "                                                  decoder_out])\n",
    "    decoder_concat = Concatenate(axis=-1, name='concat')(\n",
    "                                    [decoder_out, attn_out])\n",
    "    decoder_pred = time_distributed(decoder_concat)\n",
    "\n",
    "    decoder = Model( inputs=[encoder_seq_states, decoder_init_state, decoder_inputs],\n",
    "                           outputs=[decoder_pred, attn_states, decoder_state] )\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f787c",
   "metadata": {},
   "source": [
    "#### Inferenzmodell laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1c27da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 19)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 19, 64)       2258368     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bi_gru (Bidirectional)  [(None, 19, 128), (N 49920       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_concat (Concatenate)    (None, 128)          0           encoder_bi_gru[0][1]             \n",
      "                                                                 encoder_bi_gru[0][2]             \n",
      "==================================================================================================\n",
      "Total params: 2,308,288\n",
      "Trainable params: 2,308,288\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_word_inputs (InputLayer [(1, 1)]             0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_emb (Embedding)         multiple             1042624     decoder_word_inputs[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_init (InputLayer)       [(1, 128)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               multiple             74496       decoder_emb[1][0]                \n",
      "                                                                 decoder_init[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_seq_states (InputLayer) [(1, 19, 128)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer multiple             32896       encoder_seq_states[0][0]         \n",
      "                                                                 decoder_gru[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (1, 1, 256)          0           decoder_gru[1][0]                \n",
      "                                                                 attention_layer[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_layer (TimeDis multiple             4186787     concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,336,803\n",
      "Trainable params: 5,336,803\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, decoder = get_inference_model( model, len_seq_encoder=19)\n",
    "encoder.summary(), decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e76d1",
   "metadata": {},
   "source": [
    "### 06 Schätzungen durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24591ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as  np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def make_predictions(x_pred:str, encoder, decoder, \n",
    "                     tok_encoder, tok_decoder, \n",
    "                     seq_len_encoder=19, seq_len_decoder=26):\n",
    "    print(x_pred)\n",
    "    x_pred = tok_encoder.texts_to_sequences([x_pred])\n",
    "    x_pred = pad_sequences( x_pred, maxlen=seq_len_encoder,\n",
    "                            padding='post',\n",
    "                            truncating='post')\n",
    "    en_seq_state, en_state = encoder.predict(x_pred)\n",
    "    dec_state = en_state\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tok_en.word_index['<start>']\n",
    "    attn = []\n",
    "    print('translated:')\n",
    "    for i in range(seq_len_decoder):\n",
    "        dec_out, attention, dec_state = \\\n",
    "            decoder.predict([en_seq_state, dec_state, target_seq])\n",
    "        idx_word = np.argmax(dec_out[0][0])\n",
    "        if idx_word == 0:\n",
    "            break\n",
    "        print(tok_decoder.index_word[idx_word], end=' ')\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = idx_word\n",
    "        attn.append(attention)\n",
    "    return attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eddf41f",
   "metadata": {},
   "source": [
    "#### Übersetzung mit Beispielsatz erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2806f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auf der anderen seite der straße steht ein baum\n",
      "translated:\n",
      "there is a tree across the street "
     ]
    }
   ],
   "source": [
    "x_pred = 'auf der anderen seite der straße steht ein baum'\n",
    "attn = make_predictions(x_pred, encoder, \n",
    "                    decoder, tok_de, tok_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f357c3d",
   "metadata": {},
   "source": [
    "#### Darstellung der Attention-Gewichte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f43f7f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "attn = np.array(attn)\n",
    "attn.shape\n",
    "attn = attn.reshape(7, 19)\n",
    "\n",
    "satz = '''auf der anderen seite der straße steht ein baum <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>'''.split(' ')\n",
    "\n",
    "plt.imshow(attn)\n",
    "plt.xticks(range(0,19),\n",
    "           satz, rotation=90)\n",
    "plt.yticks(range(0,7), ['there', 'is', 'a', 'tree', \n",
    "                         'across', 'the', 'street'])\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
