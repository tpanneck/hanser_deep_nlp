{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e9ecf44",
      "metadata": {
        "id": "3e9ecf44"
      },
      "source": [
        "# Kapitel 10.3.2\n",
        "## Encoder-Decoder-Modelle mit Attention-Mechanismus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tpanneck/hanser_deep_nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CdMD_xCAN6h",
        "outputId": "40e939e4-46ce-410f-d6f1-91ea865820f8"
      },
      "id": "6CdMD_xCAN6h",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hanser_deep_nlp'...\n",
            "remote: Enumerating objects: 193, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 193 (delta 7), reused 6 (delta 2), pack-reused 175\u001b[K\n",
            "Receiving objects: 100% (193/193), 329.07 MiB | 9.09 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "Updating files: 100% (87/87), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f468131",
      "metadata": {
        "id": "6f468131"
      },
      "source": [
        "### 01 - Laden relevanter Klassen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hanser_deep_nlp/10_Sequence-to-Sequence-Modelle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJDa2Ax4AUkM",
        "outputId": "7ebdffbc-410c-4756-be56-8ff053048bfe"
      },
      "id": "tJDa2Ax4AUkM",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hanser_deep_nlp/10_Sequence-to-Sequence-Modelle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "60324896",
      "metadata": {
        "scrolled": true,
        "id": "60324896"
      },
      "outputs": [],
      "source": [
        "### Laden relevanter Klassen\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Input, Bidirectional, Embedding, GRU, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "### Eigene Klassen (liegen im aktuellen Verzeichnis)\n",
        "from attention_layer import AttentionLayer\n",
        "import load_translation_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c09d679",
      "metadata": {
        "id": "0c09d679"
      },
      "source": [
        "### 02 - Trainingsdaten laden\n",
        "Unter Verwendung der Funktion *load_data* aus der Datei *load_translation_data.py* - liegt im aktuellen Verzeichnis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "94bc132f",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94bc132f",
        "outputId": "885736f0-7c12-463e-abfa-a6a11bbcc0d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Geh.', 'Hallo!', 'Grüß Gott!', 'Lauf!', 'Lauf!'] ['<start> Go.', '<start> Hi.', '<start> Hi.', '<start> Run!', '<start> Run.'] ['Go.', 'Hi.', 'Hi.', 'Run!', 'Run.']\n",
            "[[609], [1742], [4275, 1540], [4644], [4644]] [[1, 44], [1, 2152], [1, 2152], [1, 465], [1, 465]] [[44], [2152], [2152], [465], [465]]\n",
            "max length german 19\n",
            "max length english 25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((220672, 19),\n",
              " (220672, 25),\n",
              " (220672, 25),\n",
              " <keras.src.preprocessing.text.Tokenizer at 0x7ee9174dd3c0>,\n",
              " <keras.src.preprocessing.text.Tokenizer at 0x7ee9174dd2a0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X1_pad, X2_pad, y_pad = load_translation_data.load_data(new_tokenizer=True)\n",
        "tok_de, tok_en = load_translation_data.load_tokenizer()\n",
        "X1_pad.shape, X2_pad.shape, y_pad.shape, tok_de, tok_en"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "804be314",
      "metadata": {
        "id": "804be314"
      },
      "source": [
        "### 03 - Attention-Modell für Training anlegen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "84589364",
      "metadata": {
        "id": "84589364"
      },
      "outputs": [],
      "source": [
        "def get_attention_model( seq_len_encoder: int,\n",
        "                         seq_len_decoder: int,\n",
        "                         num_words_encoder: int,\n",
        "                         num_words_decoder: int,\n",
        "                         vec_dim = 64, hidden_size = 64,\n",
        "                         ):\n",
        "\n",
        "    encoder_inputs = Input(shape=(seq_len_encoder,), name='encoder_inputs')\n",
        "    decoder_inputs = Input(shape=(seq_len_decoder,), name='decoder_inputs')\n",
        "\n",
        "    # Encoder\n",
        "    encoder_emb = Embedding(input_dim=num_words_encoder+1,\n",
        "                            output_dim=vec_dim,\n",
        "                            name='encoder_emb')(encoder_inputs)\n",
        "    encoder_gru = Bidirectional(GRU(hidden_size,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True), name='encoder_bi_gru')\n",
        "    encoder_out, encoder_ffw_state, encoder_bw_state = encoder_gru(encoder_emb)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_emb = Embedding(input_dim=num_words_decoder+1,\n",
        "                            output_dim=vec_dim,\n",
        "                            name='decoder_emb')(decoder_inputs)\n",
        "    decoder_gru = GRU(hidden_size*2, return_sequences=True,\n",
        "                return_state=True, name='decoder_gru')\n",
        "    encoder_state = Concatenate(axis=-1,\n",
        "                     name='concate_encoder')([encoder_ffw_state, encoder_bw_state])\n",
        "    decoder_out, decoder_state = decoder_gru(decoder_emb,\n",
        "                            initial_state=encoder_state)\n",
        "    # Attention layer\n",
        "    attn_layer = AttentionLayer(name='attention_layer')\n",
        "    attn_out, attn_states = attn_layer([encoder_out, decoder_out])\n",
        "\n",
        "    decoder_concat = Concatenate(axis=-1, name='concat_layer')([decoder_out, attn_out])\n",
        "    dense = Dense(num_words_decoder+1, activation='softmax', name='softmax_layer')\n",
        "    dense_time = TimeDistributed(dense, name='time_distributed_layer')\n",
        "    decoder_pred = dense_time(decoder_concat)\n",
        "\n",
        "    # Model\n",
        "    model = Model( inputs=[encoder_inputs, decoder_inputs],\n",
        "                        outputs=decoder_pred)\n",
        "    model.compile( optimizer='adam',\n",
        "                        loss='sparse_categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c307a1d0",
      "metadata": {
        "id": "c307a1d0"
      },
      "source": [
        "#### Trainingsmodell laden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "46955104",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46955104",
        "outputId": "fd1060aa-ed3d-438c-f21e-65903823dc47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, 19)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_emb (Embedding)     (None, 19, 64)               2258368   ['encoder_inputs[0][0]']      \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, 25)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_bi_gru (Bidirectio  [(None, 19, 128),            49920     ['encoder_emb[0][0]']         \n",
            " nal)                         (None, 64),                                                         \n",
            "                              (None, 64)]                                                         \n",
            "                                                                                                  \n",
            " decoder_emb (Embedding)     (None, 25, 64)               1042624   ['decoder_inputs[0][0]']      \n",
            "                                                                                                  \n",
            " concate_encoder (Concatena  (None, 128)                  0         ['encoder_bi_gru[0][1]',      \n",
            " te)                                                                 'encoder_bi_gru[0][2]']      \n",
            "                                                                                                  \n",
            " decoder_gru (GRU)           [(None, 25, 128),            74496     ['decoder_emb[0][0]',         \n",
            "                              (None, 128)]                           'concate_encoder[0][0]']     \n",
            "                                                                                                  \n",
            " attention_layer (Attention  ((None, 25, 128),            32896     ['encoder_bi_gru[0][0]',      \n",
            " Layer)                       (None, 25, 19))                        'decoder_gru[0][0]']         \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)  (None, 25, 256)              0         ['decoder_gru[0][0]',         \n",
            "                                                                     'attention_layer[0][0]']     \n",
            "                                                                                                  \n",
            " time_distributed_layer (Ti  (None, 25, 16291)            4186787   ['concat_layer[0][0]']        \n",
            " meDistributed)                                                                                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7645091 (29.16 MB)\n",
            "Trainable params: 7645091 (29.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = get_attention_model( seq_len_encoder=X1_pad.shape[1],\n",
        "                             seq_len_decoder=X2_pad.shape[1],\n",
        "                             num_words_encoder=len(tok_de.word_index),\n",
        "                             num_words_decoder=len(tok_en.word_index) )\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47eb3a49",
      "metadata": {
        "id": "47eb3a49"
      },
      "source": [
        "### 04 - Modell kompilieren, EarlyStopping und Checkpoints anlegen und Training starten\n",
        "Hinweis: Trainingsprozess ist hier nur angedeutet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3497ca5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3497ca5a",
        "outputId": "a96571bc-fec9-4ad5-9586-9cab556fad0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1552/1552 [==============================] - ETA: 0s - loss: 1.4267 - accuracy: 0.7984"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1552/1552 [==============================] - 139s 84ms/step - loss: 1.4267 - accuracy: 0.7984 - val_loss: 2.4296 - val_accuracy: 0.6247\n",
            "Epoch 2/20\n",
            "1552/1552 [==============================] - 115s 74ms/step - loss: 0.8388 - accuracy: 0.8553 - val_loss: 1.9186 - val_accuracy: 0.6946\n",
            "Epoch 3/20\n",
            "1552/1552 [==============================] - 116s 75ms/step - loss: 0.5312 - accuracy: 0.9019 - val_loss: 1.6401 - val_accuracy: 0.7344\n",
            "Epoch 4/20\n",
            "1552/1552 [==============================] - 114s 74ms/step - loss: 0.3856 - accuracy: 0.9232 - val_loss: 1.5535 - val_accuracy: 0.7482\n",
            "Epoch 5/20\n",
            "1552/1552 [==============================] - 116s 75ms/step - loss: 0.3081 - accuracy: 0.9346 - val_loss: 1.4731 - val_accuracy: 0.7608\n",
            "Epoch 6/20\n",
            "1552/1552 [==============================] - 114s 74ms/step - loss: 0.2593 - accuracy: 0.9422 - val_loss: 1.4627 - val_accuracy: 0.7647\n",
            "Epoch 7/20\n",
            "1552/1552 [==============================] - 114s 74ms/step - loss: 0.2253 - accuracy: 0.9480 - val_loss: 1.4859 - val_accuracy: 0.7646\n",
            "Epoch 8/20\n",
            "1552/1552 [==============================] - 115s 74ms/step - loss: 0.2001 - accuracy: 0.9525 - val_loss: 1.5082 - val_accuracy: 0.7631\n",
            "Epoch 9/20\n",
            "1552/1552 [==============================] - 116s 75ms/step - loss: 0.1811 - accuracy: 0.9560 - val_loss: 1.5094 - val_accuracy: 0.7657\n"
          ]
        }
      ],
      "source": [
        "model.compile( optimizer='adam',\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "stopping = EarlyStopping( monitor='val_loss',\n",
        "                         patience=3,\n",
        "                         restore_best_weights=False)\n",
        "checkpoint = ModelCheckpoint( filepath='SeqToSeq_bi_attention.h5',\n",
        "                              monitor='val_loss',\n",
        "                              save_best_only=True)\n",
        "\n",
        "history = model.fit([ X1_pad, X2_pad], y_pad,\n",
        "                        epochs=20,\n",
        "                        batch_size=128,\n",
        "                        validation_split=.1,\n",
        "                        callbacks=[stopping, checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "613b9096",
      "metadata": {
        "id": "613b9096"
      },
      "source": [
        "#### Angelerntes Modell laden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3c3cf3f0",
      "metadata": {
        "id": "3c3cf3f0"
      },
      "outputs": [],
      "source": [
        "model = load_model( 'SeqToSeq_bi_attention.h5',\n",
        "                    custom_objects={'AttentionLayer':AttentionLayer})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb6aba5b",
      "metadata": {
        "id": "bb6aba5b"
      },
      "source": [
        "### 05 - Inferenzmodell aufbauen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "814cae02",
      "metadata": {
        "id": "814cae02"
      },
      "outputs": [],
      "source": [
        "def get_inference_model(model, len_seq_encoder: int, hidden_size=64):\n",
        "\n",
        "    batch_size = 1\n",
        "\n",
        "    # Encoder\n",
        "    encoder_in = model.get_layer('encoder_inputs').input\n",
        "    encoder_output, encoder_ffw_h, encoder_bw_h = \\\n",
        "                        model.get_layer('encoder_bi_gru').output\n",
        "    encoder_states = Concatenate( axis=-1, name='encoder_concat')(\n",
        "                                  [encoder_ffw_h, encoder_bw_h])\n",
        "    encoder = Model( inputs=encoder_in,\n",
        "                     outputs=[encoder_output, encoder_states])\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(batch_shape=(batch_size, 1),\n",
        "                               name='decoder_word_inputs')\n",
        "    encoder_seq_states = Input(batch_shape=(batch_size,\n",
        "                                            len_seq_encoder,\n",
        "                                            hidden_size*2), name='encoder_seq_states')\n",
        "    decoder_init_state = Input(batch_shape=(batch_size,\n",
        "                                            hidden_size*2), name='decoder_init')\n",
        "\n",
        "    decoder_emb = model.get_layer('decoder_emb')\n",
        "    decoder_gru = model.get_layer('decoder_gru')\n",
        "    decoder_att = model.get_layer('attention_layer')\n",
        "    time_distributed = model.get_layer('time_distributed_layer')\n",
        "\n",
        "    decoder_emb = decoder_emb(decoder_inputs)\n",
        "    decoder_out, decoder_state = decoder_gru(decoder_emb,\n",
        "                                                     initial_state=decoder_init_state)\n",
        "    attn_out, attn_states = decoder_att([ encoder_seq_states,\n",
        "                                                  decoder_out])\n",
        "    decoder_concat = Concatenate(axis=-1, name='concat')(\n",
        "                                    [decoder_out, attn_out])\n",
        "    decoder_pred = time_distributed(decoder_concat)\n",
        "\n",
        "    decoder = Model( inputs=[encoder_seq_states, decoder_init_state, decoder_inputs],\n",
        "                           outputs=[decoder_pred, attn_states, decoder_state] )\n",
        "    return encoder, decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "534f787c",
      "metadata": {
        "id": "534f787c"
      },
      "source": [
        "#### Inferenzmodell laden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b1c27da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1c27da1",
        "outputId": "c260d3f9-7cb4-4d66-abdb-9ecf32cef0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, 19)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_emb (Embedding)     (None, 19, 64)               2258368   ['encoder_inputs[0][0]']      \n",
            "                                                                                                  \n",
            " encoder_bi_gru (Bidirectio  [(None, 19, 128),            49920     ['encoder_emb[0][0]']         \n",
            " nal)                         (None, 64),                                                         \n",
            "                              (None, 64)]                                                         \n",
            "                                                                                                  \n",
            " encoder_concat (Concatenat  (None, 128)                  0         ['encoder_bi_gru[0][1]',      \n",
            " e)                                                                  'encoder_bi_gru[0][2]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2308288 (8.81 MB)\n",
            "Trainable params: 2308288 (8.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " decoder_word_inputs (Input  [(1, 1)]                     0         []                            \n",
            " Layer)                                                                                           \n",
            "                                                                                                  \n",
            " decoder_emb (Embedding)     multiple                     1042624   ['decoder_word_inputs[0][0]'] \n",
            "                                                                                                  \n",
            " decoder_init (InputLayer)   [(1, 128)]                   0         []                            \n",
            "                                                                                                  \n",
            " decoder_gru (GRU)           multiple                     74496     ['decoder_emb[1][0]',         \n",
            "                                                                     'decoder_init[0][0]']        \n",
            "                                                                                                  \n",
            " encoder_seq_states (InputL  [(1, 19, 128)]               0         []                            \n",
            " ayer)                                                                                            \n",
            "                                                                                                  \n",
            " attention_layer (Attention  multiple                     32896     ['encoder_seq_states[0][0]',  \n",
            " Layer)                                                              'decoder_gru[1][0]']         \n",
            "                                                                                                  \n",
            " concat (Concatenate)        (1, 1, 256)                  0         ['decoder_gru[1][0]',         \n",
            "                                                                     'attention_layer[1][0]']     \n",
            "                                                                                                  \n",
            " time_distributed_layer (Ti  multiple                     4186787   ['concat[0][0]']              \n",
            " meDistributed)                                                                                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5336803 (20.36 MB)\n",
            "Trainable params: 5336803 (20.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "encoder, decoder = get_inference_model( model, len_seq_encoder=19)\n",
        "encoder.summary(), decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee1e76d1",
      "metadata": {
        "id": "ee1e76d1"
      },
      "source": [
        "### 06 Schätzungen durchführen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "24591ad1",
      "metadata": {
        "id": "24591ad1"
      },
      "outputs": [],
      "source": [
        "import numpy as  np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def make_predictions(x_pred:str, encoder, decoder,\n",
        "                     tok_encoder, tok_decoder,\n",
        "                     seq_len_encoder=19, seq_len_decoder=26):\n",
        "    print(x_pred)\n",
        "    x_pred = tok_encoder.texts_to_sequences([x_pred])\n",
        "    x_pred = pad_sequences( x_pred, maxlen=seq_len_encoder,\n",
        "                            padding='post',\n",
        "                            truncating='post')\n",
        "    en_seq_state, en_state = encoder.predict(x_pred)\n",
        "    dec_state = en_state\n",
        "\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = tok_en.word_index['<start>']\n",
        "    attn = []\n",
        "    print('translated:')\n",
        "    for i in range(seq_len_decoder):\n",
        "        dec_out, attention, dec_state = \\\n",
        "            decoder.predict([en_seq_state, dec_state, target_seq])\n",
        "        idx_word = np.argmax(dec_out[0][0])\n",
        "        if idx_word == 0:\n",
        "            break\n",
        "        print(tok_decoder.index_word[idx_word], end=' ')\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = idx_word\n",
        "        attn.append(attention)\n",
        "    return attn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eddf41f",
      "metadata": {
        "id": "9eddf41f"
      },
      "source": [
        "#### Übersetzung mit Beispielsatz erzeugen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b2806f52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2806f52",
        "outputId": "847c168e-8c64-429f-e245-34f0fdbb0d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auf der anderen seite der straße steht ein baum\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "translated:\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        }
      ],
      "source": [
        "x_pred = 'auf der anderen seite der straße steht ein baum'\n",
        "attn = make_predictions(x_pred, encoder, decoder, tok_de, tok_en)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f357c3d",
      "metadata": {
        "id": "3f357c3d"
      },
      "source": [
        "#### Darstellung der Attention-Gewichte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f43f7f99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "f43f7f99",
        "outputId": "cc1a45f5-adad-4108-c722-08dbec25d9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 19)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "attn = np.array(attn)\n",
        "print(attn.shape)\n",
        "attn = attn.reshape(8, 19)\n",
        "\n",
        "satz = '''auf der anderen seite der straße steht ein baum <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>'''.split(' ')\n",
        "\n",
        "plt.imshow(attn)\n",
        "plt.xticks(range(0,19), satz, rotation=90)\n",
        "plt.yticks(range(0,7), ['there', 'is', 'a', 'tree', 'across', 'the', 'street'])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git status\n",
        "# !git add ../Data/tok_de_trans.pkl\n",
        "# !git add ../Data/tok_en_trans.pkl\n",
        "#!git config --global user.email \"panneck.conradi@gmail.com\"\n",
        "#!git config --global user.name \"Thorsten Panneck-Conradi\"\n",
        "#!git commit -m 'updated h5 and pkl after local run'\n",
        "#!git pull\n",
        "!git remote set-url origin https://tpanneck:github_PAT@github.com/tpanneck/hanser_deep_nlp\n",
        "!git push"
      ],
      "metadata": {
        "id": "p0eHGuGkT8eq",
        "outputId": "3bf81afa-9781-4127-81a3-87c82fbb05a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p0eHGuGkT8eq",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 13, done.\n",
            "Counting objects:   7% (1/13)\rCounting objects:  15% (2/13)\rCounting objects:  23% (3/13)\rCounting objects:  30% (4/13)\rCounting objects:  38% (5/13)\rCounting objects:  46% (6/13)\rCounting objects:  53% (7/13)\rCounting objects:  61% (8/13)\rCounting objects:  69% (9/13)\rCounting objects:  76% (10/13)\rCounting objects:  84% (11/13)\rCounting objects:  92% (12/13)\rCounting objects: 100% (13/13)\rCounting objects: 100% (13/13), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (7/7), done.\n",
            "Writing objects: 100% (7/7), 76.87 MiB | 10.70 MiB/s, done.\n",
            "Total 7 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: See https://gh.io/lfs for more information.\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: File 10_Sequence-to-Sequence-Modelle/SeqToSeq_bi_attention.h5 is 87.57 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\u001b[K\n",
            "To https://github.com/tpanneck/hanser_deep_nlp\n",
            "   bba3dc2..14e8834  master -> master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pky4D_aAWwJJ"
      },
      "id": "pky4D_aAWwJJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}