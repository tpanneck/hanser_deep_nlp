{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e9ecf44",
      "metadata": {
        "id": "3e9ecf44"
      },
      "source": [
        "# Kapitel 10.3.2\n",
        "## Encoder-Decoder-Modelle mit Attention-Mechanismus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"panneck.conradi@gmail.com\"\n",
        "!git config --global user.name \"Thorsten Panneck-Conradi\"\n",
        "# !git remote set-url origin https://tpanneck:github_PAT@github.com/tpanneck/hanser_deep_nlp\n",
        "!git clone https://github.com/tpanneck/hanser_deep_nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CdMD_xCAN6h",
        "outputId": "22b9cd73-1d88-4e9b-9a60-d2855d133059"
      },
      "id": "6CdMD_xCAN6h",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Cloning into 'hanser_deep_nlp'...\n",
            "remote: Enumerating objects: 204, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 204 (delta 12), reused 23 (delta 9), pack-reused 175\u001b[K\n",
            "Receiving objects: 100% (204/204), 405.95 MiB | 13.73 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "Updating files: 100% (87/87), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f468131",
      "metadata": {
        "id": "6f468131"
      },
      "source": [
        "### 01 - Laden relevanter Klassen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hanser_deep_nlp/10_Sequence-to-Sequence-Modelle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJDa2Ax4AUkM",
        "outputId": "9480eb9f-241f-45ea-c308-0cc88a79074e"
      },
      "id": "tJDa2Ax4AUkM",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hanser_deep_nlp/10_Sequence-to-Sequence-Modelle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "60324896",
      "metadata": {
        "scrolled": true,
        "id": "60324896"
      },
      "outputs": [],
      "source": [
        "### Laden relevanter Klassen\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Input, Bidirectional, Embedding, GRU, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "### Eigene Klassen (liegen im aktuellen Verzeichnis)\n",
        "from attention_layer import AttentionLayer\n",
        "import load_translation_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c09d679",
      "metadata": {
        "id": "0c09d679"
      },
      "source": [
        "### 02 - Trainingsdaten laden\n",
        "Unter Verwendung der Funktion *load_data* aus der Datei *load_translation_data.py* - liegt im aktuellen Verzeichnis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "94bc132f",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94bc132f",
        "outputId": "820f24e4-6610-4e11-8bb7-b546a4b58796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Geh.', 'Hallo!', 'Grüß Gott!', 'Lauf!', 'Lauf!'] ['<start> Go.', '<start> Hi.', '<start> Hi.', '<start> Run!', '<start> Run.'] ['Go.', 'Hi.', 'Hi.', 'Run!', 'Run.']\n",
            "[[609], [1742], [4275, 1540], [4644], [4644]] [[1, 44], [1, 2152], [1, 2152], [1, 465], [1, 465]] [[44], [2152], [2152], [465], [465]]\n",
            "max length german 19\n",
            "max length english 25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((220672, 19),\n",
              " (220672, 25),\n",
              " (220672, 25),\n",
              " <keras.src.preprocessing.text.Tokenizer at 0x7bf3d4722ad0>,\n",
              " <keras.src.preprocessing.text.Tokenizer at 0x7bf48281fa90>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X1_pad, X2_pad, y_pad = load_translation_data.load_data(new_tokenizer=True)\n",
        "tok_de, tok_en = load_translation_data.load_tokenizer()\n",
        "X1_pad.shape, X2_pad.shape, y_pad.shape, tok_de, tok_en"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "804be314",
      "metadata": {
        "id": "804be314"
      },
      "source": [
        "### 03 - Attention-Modell für Training anlegen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "84589364",
      "metadata": {
        "id": "84589364"
      },
      "outputs": [],
      "source": [
        "def get_attention_model( seq_len_encoder: int,\n",
        "                         seq_len_decoder: int,\n",
        "                         num_words_encoder: int,\n",
        "                         num_words_decoder: int,\n",
        "                         vec_dim = 64, hidden_size = 64,\n",
        "                         ):\n",
        "\n",
        "    encoder_inputs = Input(shape=(seq_len_encoder,), name='encoder_inputs')\n",
        "    decoder_inputs = Input(shape=(seq_len_decoder,), name='decoder_inputs')\n",
        "\n",
        "    # Encoder\n",
        "    encoder_emb = Embedding(input_dim=num_words_encoder+1,\n",
        "                            output_dim=vec_dim,\n",
        "                            name='encoder_emb')(encoder_inputs)\n",
        "    encoder_gru = Bidirectional(GRU(hidden_size,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True), name='encoder_bi_gru')\n",
        "    encoder_out, encoder_ffw_state, encoder_bw_state = encoder_gru(encoder_emb)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_emb = Embedding(input_dim=num_words_decoder+1,\n",
        "                            output_dim=vec_dim,\n",
        "                            name='decoder_emb')(decoder_inputs)\n",
        "    decoder_gru = GRU(hidden_size*2, return_sequences=True,\n",
        "                return_state=True, name='decoder_gru')\n",
        "    encoder_state = Concatenate(axis=-1,\n",
        "                     name='concate_encoder')([encoder_ffw_state, encoder_bw_state])\n",
        "    decoder_out, decoder_state = decoder_gru(decoder_emb,\n",
        "                            initial_state=encoder_state)\n",
        "    # Attention layer\n",
        "    attn_layer = AttentionLayer(name='attention_layer')\n",
        "    attn_out, attn_states = attn_layer([encoder_out, decoder_out])\n",
        "\n",
        "    decoder_concat = Concatenate(axis=-1, name='concat_layer')([decoder_out, attn_out])\n",
        "    dense = Dense(num_words_decoder+1, activation='softmax', name='softmax_layer')\n",
        "    dense_time = TimeDistributed(dense, name='time_distributed_layer')\n",
        "    decoder_pred = dense_time(decoder_concat)\n",
        "\n",
        "    # Model\n",
        "    model = Model( inputs=[encoder_inputs, decoder_inputs],\n",
        "                        outputs=decoder_pred)\n",
        "    model.compile( optimizer='adam',\n",
        "                        loss='sparse_categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c307a1d0",
      "metadata": {
        "id": "c307a1d0"
      },
      "source": [
        "#### Trainingsmodell laden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "46955104",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46955104",
        "outputId": "fd1060aa-ed3d-438c-f21e-65903823dc47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, 19)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_emb (Embedding)     (None, 19, 64)               2258368   ['encoder_inputs[0][0]']      \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, 25)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_bi_gru (Bidirectio  [(None, 19, 128),            49920     ['encoder_emb[0][0]']         \n",
            " nal)                         (None, 64),                                                         \n",
            "                              (None, 64)]                                                         \n",
            "                                                                                                  \n",
            " decoder_emb (Embedding)     (None, 25, 64)               1042624   ['decoder_inputs[0][0]']      \n",
            "                                                                                                  \n",
            " concate_encoder (Concatena  (None, 128)                  0         ['encoder_bi_gru[0][1]',      \n",
            " te)                                                                 'encoder_bi_gru[0][2]']      \n",
            "                                                                                                  \n",
            " decoder_gru (GRU)           [(None, 25, 128),            74496     ['decoder_emb[0][0]',         \n",
            "                              (None, 128)]                           'concate_encoder[0][0]']     \n",
            "                                                                                                  \n",
            " attention_layer (Attention  ((None, 25, 128),            32896     ['encoder_bi_gru[0][0]',      \n",
            " Layer)                       (None, 25, 19))                        'decoder_gru[0][0]']         \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)  (None, 25, 256)              0         ['decoder_gru[0][0]',         \n",
            "                                                                     'attention_layer[0][0]']     \n",
            "                                                                                                  \n",
            " time_distributed_layer (Ti  (None, 25, 16291)            4186787   ['concat_layer[0][0]']        \n",
            " meDistributed)                                                                                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7645091 (29.16 MB)\n",
            "Trainable params: 7645091 (29.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = get_attention_model( seq_len_encoder=X1_pad.shape[1],\n",
        "                             seq_len_decoder=X2_pad.shape[1],\n",
        "                             num_words_encoder=len(tok_de.word_index),\n",
        "                             num_words_decoder=len(tok_en.word_index) )\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47eb3a49",
      "metadata": {
        "id": "47eb3a49"
      },
      "source": [
        "### 04 - Modell kompilieren, EarlyStopping und Checkpoints anlegen und Training starten\n",
        "Hinweis: Trainingsprozess ist hier nur angedeutet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3497ca5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3497ca5a",
        "outputId": "a96571bc-fec9-4ad5-9586-9cab556fad0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1552/1552 [==============================] - ETA: 0s - loss: 1.4267 - accuracy: 0.7984"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1552/1552 [==============================] - 139s 84ms/step - loss: 1.4267 - accuracy: 0.7984 - val_loss: 2.4296 - val_accuracy: 0.6247\n",
            "Epoch 2/20\n",
            "1552/1552 [==============================] - 115s 74ms/step - loss: 0.8388 - accuracy: 0.8553 - val_loss: 1.9186 - val_accuracy: 0.6946\n",
            "Epoch 3/20\n",
            "1552/1552 [==============================] - 116s 75ms/step - loss: 0.5312 - accuracy: 0.9019 - val_loss: 1.6401 - val_accuracy: 0.7344\n",
            "Epoch 4/20\n",
            "1552/1552 [==============================] - 114s 74ms/step - loss: 0.3856 - accuracy: 0.9232 - val_loss: 1.5535 - val_accuracy: 0.7482\n",
            "Epoch 5/20\n",
            "1552/1552 [==============================] - 116s 75ms/step - loss: 0.3081 - accuracy: 0.9346 - val_loss: 1.4731 - val_accuracy: 0.7608\n",
            "Epoch 6/20\n",
            "1552/1552 [==============================] - 114s 74ms/step - loss: 0.2593 - accuracy: 0.9422 - val_loss: 1.4627 - val_accuracy: 0.7647\n",
            "Epoch 7/20\n",
            "1552/1552 [==============================] - 114s 74ms/step - loss: 0.2253 - accuracy: 0.9480 - val_loss: 1.4859 - val_accuracy: 0.7646\n",
            "Epoch 8/20\n",
            "1552/1552 [==============================] - 115s 74ms/step - loss: 0.2001 - accuracy: 0.9525 - val_loss: 1.5082 - val_accuracy: 0.7631\n",
            "Epoch 9/20\n",
            "1552/1552 [==============================] - 116s 75ms/step - loss: 0.1811 - accuracy: 0.9560 - val_loss: 1.5094 - val_accuracy: 0.7657\n"
          ]
        }
      ],
      "source": [
        "model.compile( optimizer='adam',\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "stopping = EarlyStopping( monitor='val_loss',\n",
        "                         patience=3,\n",
        "                         restore_best_weights=False)\n",
        "checkpoint = ModelCheckpoint( filepath='SeqToSeq_bi_attention.h5',\n",
        "                              monitor='val_loss',\n",
        "                              save_best_only=True)\n",
        "\n",
        "history = model.fit([ X1_pad, X2_pad], y_pad,\n",
        "                        epochs=20,\n",
        "                        batch_size=128,\n",
        "                        validation_split=.1,\n",
        "                        callbacks=[stopping, checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "613b9096",
      "metadata": {
        "id": "613b9096"
      },
      "source": [
        "#### Angelerntes Modell laden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3c3cf3f0",
      "metadata": {
        "id": "3c3cf3f0"
      },
      "outputs": [],
      "source": [
        "model = load_model( 'SeqToSeq_bi_attention.h5',\n",
        "                    custom_objects={'AttentionLayer':AttentionLayer})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb6aba5b",
      "metadata": {
        "id": "bb6aba5b"
      },
      "source": [
        "### 05 - Inferenzmodell aufbauen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "814cae02",
      "metadata": {
        "id": "814cae02"
      },
      "outputs": [],
      "source": [
        "def get_inference_model(model, len_seq_encoder: int, hidden_size=64):\n",
        "\n",
        "    batch_size = 1\n",
        "\n",
        "    # Encoder\n",
        "    encoder_in = model.get_layer('encoder_inputs').input\n",
        "    encoder_output, encoder_ffw_h, encoder_bw_h = \\\n",
        "                        model.get_layer('encoder_bi_gru').output\n",
        "    encoder_states = Concatenate( axis=-1, name='encoder_concat')(\n",
        "                                  [encoder_ffw_h, encoder_bw_h])\n",
        "    encoder = Model( inputs=encoder_in,\n",
        "                     outputs=[encoder_output, encoder_states])\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(batch_shape=(batch_size, 1),\n",
        "                               name='decoder_word_inputs')\n",
        "    encoder_seq_states = Input(batch_shape=(batch_size,\n",
        "                                            len_seq_encoder,\n",
        "                                            hidden_size*2), name='encoder_seq_states')\n",
        "    decoder_init_state = Input(batch_shape=(batch_size,\n",
        "                                            hidden_size*2), name='decoder_init')\n",
        "\n",
        "    decoder_emb = model.get_layer('decoder_emb')\n",
        "    decoder_gru = model.get_layer('decoder_gru')\n",
        "    decoder_att = model.get_layer('attention_layer')\n",
        "    time_distributed = model.get_layer('time_distributed_layer')\n",
        "\n",
        "    decoder_emb = decoder_emb(decoder_inputs)\n",
        "    decoder_out, decoder_state = decoder_gru(decoder_emb,\n",
        "                                                     initial_state=decoder_init_state)\n",
        "    attn_out, attn_states = decoder_att([ encoder_seq_states,\n",
        "                                                  decoder_out])\n",
        "    decoder_concat = Concatenate(axis=-1, name='concat')(\n",
        "                                    [decoder_out, attn_out])\n",
        "    decoder_pred = time_distributed(decoder_concat)\n",
        "\n",
        "    decoder = Model( inputs=[encoder_seq_states, decoder_init_state, decoder_inputs],\n",
        "                           outputs=[decoder_pred, attn_states, decoder_state] )\n",
        "    return encoder, decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "534f787c",
      "metadata": {
        "id": "534f787c"
      },
      "source": [
        "#### Inferenzmodell laden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b1c27da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1c27da1",
        "outputId": "9a7f1987-0c8b-4453-e300-114a5387d4af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, 19)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_emb (Embedding)     (None, 19, 64)               2258368   ['encoder_inputs[0][0]']      \n",
            "                                                                                                  \n",
            " encoder_bi_gru (Bidirectio  [(None, 19, 128),            49920     ['encoder_emb[0][0]']         \n",
            " nal)                         (None, 64),                                                         \n",
            "                              (None, 64)]                                                         \n",
            "                                                                                                  \n",
            " encoder_concat (Concatenat  (None, 128)                  0         ['encoder_bi_gru[0][1]',      \n",
            " e)                                                                  'encoder_bi_gru[0][2]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2308288 (8.81 MB)\n",
            "Trainable params: 2308288 (8.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " decoder_word_inputs (Input  [(1, 1)]                     0         []                            \n",
            " Layer)                                                                                           \n",
            "                                                                                                  \n",
            " decoder_emb (Embedding)     multiple                     1042624   ['decoder_word_inputs[0][0]'] \n",
            "                                                                                                  \n",
            " decoder_init (InputLayer)   [(1, 128)]                   0         []                            \n",
            "                                                                                                  \n",
            " decoder_gru (GRU)           multiple                     74496     ['decoder_emb[1][0]',         \n",
            "                                                                     'decoder_init[0][0]']        \n",
            "                                                                                                  \n",
            " encoder_seq_states (InputL  [(1, 19, 128)]               0         []                            \n",
            " ayer)                                                                                            \n",
            "                                                                                                  \n",
            " attention_layer (Attention  multiple                     32896     ['encoder_seq_states[0][0]',  \n",
            " Layer)                                                              'decoder_gru[1][0]']         \n",
            "                                                                                                  \n",
            " concat (Concatenate)        (1, 1, 256)                  0         ['decoder_gru[1][0]',         \n",
            "                                                                     'attention_layer[1][0]']     \n",
            "                                                                                                  \n",
            " time_distributed_layer (Ti  multiple                     4186787   ['concat[0][0]']              \n",
            " meDistributed)                                                                                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5336803 (20.36 MB)\n",
            "Trainable params: 5336803 (20.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "encoder, decoder = get_inference_model( model, len_seq_encoder=19)\n",
        "encoder.summary(), decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee1e76d1",
      "metadata": {
        "id": "ee1e76d1"
      },
      "source": [
        "### 06 Schätzungen durchführen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "24591ad1",
      "metadata": {
        "id": "24591ad1"
      },
      "outputs": [],
      "source": [
        "import numpy as  np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def make_predictions(x_pred:str, encoder, decoder,\n",
        "                     tok_encoder, tok_decoder,\n",
        "                     seq_len_encoder=19, seq_len_decoder=26):\n",
        "    print(x_pred)\n",
        "    x_pred = tok_encoder.texts_to_sequences([x_pred])\n",
        "    x_pred = pad_sequences( x_pred, maxlen=seq_len_encoder,\n",
        "                            padding='post',\n",
        "                            truncating='post')\n",
        "    en_seq_state, en_state = encoder.predict(x_pred)\n",
        "    dec_state = en_state\n",
        "\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = tok_en.word_index['<start>']\n",
        "    attn = []\n",
        "    output = []\n",
        "    print('translated:')\n",
        "    for i in range(seq_len_decoder):\n",
        "        dec_out, attention, dec_state = \\\n",
        "            decoder.predict([en_seq_state, dec_state, target_seq])\n",
        "        idx_word = np.argmax(dec_out[0][0])\n",
        "        if idx_word == 0:\n",
        "            break\n",
        "        print(tok_decoder.index_word[idx_word], end=' ')\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = idx_word\n",
        "        attn.append(attention)\n",
        "        output.append(tok_decoder.index_word[idx_word])\n",
        "    return output, attn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eddf41f",
      "metadata": {
        "id": "9eddf41f"
      },
      "source": [
        "#### Übersetzung mit Beispielsatz erzeugen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "b2806f52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2806f52",
        "outputId": "e78c3ad3-aa70-43ce-cf19-773304fae660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Das Flugzeug fliegt immer wieder über die Stadt\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "translated:\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "['the', 'plane', 'always', 'flies', 'over', 'the', 'city']\n"
          ]
        }
      ],
      "source": [
        "x_pred = 'Das Flugzeug fliegt immer wieder über die Stadt'\n",
        "output, attn = make_predictions(x_pred, encoder, decoder, tok_de, tok_en)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f357c3d",
      "metadata": {
        "id": "3f357c3d"
      },
      "source": [
        "#### Darstellung der Attention-Gewichte"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn = np.array(attn)\n",
        "shape = attn.shape\n",
        "print(f\"{shape[0]}, {shape[3]}\" )"
      ],
      "metadata": {
        "id": "LpgwuT55gtb7",
        "outputId": "8189af53-548a-4740-d436-b2072464cce9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LpgwuT55gtb7",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7, 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f43f7f99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "f43f7f99",
        "outputId": "cd142aef-7346-45d5-be4d-b0383df714c3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "attn = np.array(attn)\n",
        "shape = attn.shape\n",
        "attn = attn.reshape(shape[0], shape[3])\n",
        "\n",
        "satz = x_pred.split(' ')\n",
        "\n",
        "plt.imshow(attn)\n",
        "plt.xticks(range(0,len(satz)), satz, rotation=90)\n",
        "plt.yticks(range(0,len(output)), output)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git status\n",
        "# !git add ../Data/tok_de_trans.pkl\n",
        "# !git add ../Data/tok_en_trans.pkl\n",
        "#!git config --global user.email \"panneck.conradi@gmail.com\"\n",
        "#!git config --global user.name \"Thorsten Panneck-Conradi\"\n",
        "#!git commit -m 'updated h5 and pkl after local run'\n",
        "#!git pull\n",
        "!git remote set-url origin https://tpanneck:github_PAT@github.com/tpanneck/hanser_deep_nlp\n",
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0eHGuGkT8eq",
        "outputId": "3bf81afa-9781-4127-81a3-87c82fbb05a3"
      },
      "id": "p0eHGuGkT8eq",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 13, done.\n",
            "Counting objects:   7% (1/13)\rCounting objects:  15% (2/13)\rCounting objects:  23% (3/13)\rCounting objects:  30% (4/13)\rCounting objects:  38% (5/13)\rCounting objects:  46% (6/13)\rCounting objects:  53% (7/13)\rCounting objects:  61% (8/13)\rCounting objects:  69% (9/13)\rCounting objects:  76% (10/13)\rCounting objects:  84% (11/13)\rCounting objects:  92% (12/13)\rCounting objects: 100% (13/13)\rCounting objects: 100% (13/13), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (7/7), done.\n",
            "Writing objects: 100% (7/7), 76.87 MiB | 10.70 MiB/s, done.\n",
            "Total 7 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: See https://gh.io/lfs for more information.\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: File 10_Sequence-to-Sequence-Modelle/SeqToSeq_bi_attention.h5 is 87.57 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\u001b[K\n",
            "To https://github.com/tpanneck/hanser_deep_nlp\n",
            "   bba3dc2..14e8834  master -> master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pky4D_aAWwJJ"
      },
      "id": "pky4D_aAWwJJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}