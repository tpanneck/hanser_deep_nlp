{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fcddd46",
   "metadata": {},
   "source": [
    "# 7.3\tPraxis des Anlernens eines konvolutionalen Netzes mit Textdaten (Rechtschreibkorrektur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc95b7",
   "metadata": {},
   "source": [
    "### 01 - Laden der Daten und des Objekts vom Typ SequenceEncoder \n",
    "Angelernt und gespeichert wurde das Objekt im Code zu Kapitel 6 - rekurrente Netze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd53a7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspelling</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elwern</td>\n",
       "      <td>eltern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemeinsan</td>\n",
       "      <td>gemeinsam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beispielsweiße</td>\n",
       "      <td>beispielsweise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>promramm</td>\n",
       "      <td>programm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeinen</td>\n",
       "      <td>keinen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      misspelling            word\n",
       "0          elwern          eltern\n",
       "1       gemeinsan       gemeinsam\n",
       "2  beispielsweiße  beispielsweise\n",
       "3        promramm        programm\n",
       "4          yeinen          keinen"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from os.path import join\n",
    "from sequence_encoder import SequenceEncoder\n",
    "\n",
    "path = r'..\\Data'\n",
    "\n",
    "## SequenceEncoder-Objekt laden\n",
    "seq_encoder = joblib.load('seq_encoder.pkl')\n",
    "\n",
    "## Daten laden\n",
    "df_train = pd.read_csv(join(path, 'train_spelling.csv'))\n",
    "df_test = pd.read_csv(join(path, 'test_spelling.csv'))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d49ea8",
   "metadata": {},
   "source": [
    "### 02 - Daten für Analyse vorbereiten\n",
    "Hier werden die x-Daten mit Hilfe des SequenceEncoder-Objekts (Methode: gen_one_hot_data) in sequenzielle One-Hot-Arrays zerlegt. Die y-Daten werden als Integers codiert (Methode: word_to_int)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd817056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12737, 15, 32), (3184, 15, 32), (12737,), (3184,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## X/y separieren\n",
    "X_train, y_train = df_train['misspelling'], df_train['word']\n",
    "X_test, y_test = df_test['misspelling'], df_test['word']\n",
    "\n",
    "## Daten mit seq_encoder umwandeln\n",
    "X_train = seq_encoder.gen_one_hot_data(X_train)\n",
    "X_test = seq_encoder.gen_one_hot_data(X_test)\n",
    "y_train = np.array([seq_encoder.word_to_int(word) for word in y_train.values])\n",
    "y_test = np.array([seq_encoder.word_to_int(word) for word in y_test.values])\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648c127",
   "metadata": {},
   "source": [
    "### 03 - Aufbau des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1bcdaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 13, 32)            3104      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                12672     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               32500     \n",
      "=================================================================\n",
      "Total params: 48,276\n",
      "Trainable params: 48,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, GRU, Dense, Conv1D, MaxPool1D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D( filters=32, \n",
    "                  input_shape=(15, 32), \n",
    "                  kernel_size=3,\n",
    "                  activation='relu'))\n",
    "model.add(Bidirectional(GRU(units=32)))\n",
    "model.add(Dense(units=500, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(  loss='sparse_categorical_crossentropy', \n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a30ec3",
   "metadata": {},
   "source": [
    "### 04 - Anlernen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9835ed28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 4s 10ms/step - loss: 5.3124 - accuracy: 0.0575 - val_loss: 4.3044 - val_accuracy: 0.1878\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 3s 8ms/step - loss: 3.5231 - accuracy: 0.3655 - val_loss: 2.8927 - val_accuracy: 0.5110\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 3s 8ms/step - loss: 2.4410 - accuracy: 0.5711 - val_loss: 2.1619 - val_accuracy: 0.5955\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 3s 9ms/step - loss: 1.8319 - accuracy: 0.6819 - val_loss: 1.6883 - val_accuracy: 0.6897\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 3s 9ms/step - loss: 1.4431 - accuracy: 0.7434 - val_loss: 1.3900 - val_accuracy: 0.7368\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 4s 9ms/step - loss: 1.1742 - accuracy: 0.7938 - val_loss: 1.1767 - val_accuracy: 0.7789\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 4s 10ms/step - loss: 0.9801 - accuracy: 0.8255 - val_loss: 1.0266 - val_accuracy: 0.7965\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 3s 9ms/step - loss: 0.8358 - accuracy: 0.8499 - val_loss: 0.9308 - val_accuracy: 0.8056\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 3s 8ms/step - loss: 0.7224 - accuracy: 0.8685 - val_loss: 0.8566 - val_accuracy: 0.8229\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 3s 8ms/step - loss: 0.6362 - accuracy: 0.8840 - val_loss: 0.7937 - val_accuracy: 0.8175\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 3s 9ms/step - loss: 0.5602 - accuracy: 0.8979 - val_loss: 0.6990 - val_accuracy: 0.8417\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 3s 8ms/step - loss: 0.4994 - accuracy: 0.9063 - val_loss: 0.6460 - val_accuracy: 0.8533\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 3s 8ms/step - loss: 0.4509 - accuracy: 0.9127 - val_loss: 0.6037 - val_accuracy: 0.8637\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 3s 9ms/step - loss: 0.4065 - accuracy: 0.9241 - val_loss: 0.5685 - val_accuracy: 0.8665\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 3s 9ms/step - loss: 0.3696 - accuracy: 0.9292 - val_loss: 0.5407 - val_accuracy: 0.8693\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 3s 8ms/step - loss: 0.3376 - accuracy: 0.9380 - val_loss: 0.5243 - val_accuracy: 0.8753\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 3s 9ms/step - loss: 0.3083 - accuracy: 0.9427 - val_loss: 0.4927 - val_accuracy: 0.8725\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 3s 8ms/step - loss: 0.2800 - accuracy: 0.9487 - val_loss: 0.4824 - val_accuracy: 0.8778\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 3s 9ms/step - loss: 0.2663 - accuracy: 0.9500 - val_loss: 0.4608 - val_accuracy: 0.8854\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 3s 8ms/step - loss: 0.2424 - accuracy: 0.9545 - val_loss: 0.4673 - val_accuracy: 0.8788\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "stopping = EarlyStopping( monitor='val_loss', \n",
    "                          patience=1,\n",
    "                          restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint( filepath='model_auto_correction_bid.h5',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "history = model.fit( X_train, y_train, \n",
    "                     epochs=100,\n",
    "                     batch_size=32,\n",
    "                     callbacks=[stopping, checkpoint],\n",
    "                     validation_data=(X_test, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4216f9a",
   "metadata": {},
   "source": [
    "### 05 - Tests durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab7ab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allein\n",
      "frage\n",
      "beispiel\n"
     ]
    }
   ],
   "source": [
    "test_example = np.array(['alllein', 'frahe', 'beistiel'])\n",
    "test_example = seq_encoder.gen_one_hot_data(test_example)\n",
    "\n",
    "pred_word_prob = model.predict(test_example)\n",
    "pred_word_idx = np.argmax(pred_word_prob, axis=1)\n",
    "\n",
    "## Ergebnisse decodieren\n",
    "for idx in pred_word_idx:\n",
    "    print(seq_encoder.int_to_word(idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
