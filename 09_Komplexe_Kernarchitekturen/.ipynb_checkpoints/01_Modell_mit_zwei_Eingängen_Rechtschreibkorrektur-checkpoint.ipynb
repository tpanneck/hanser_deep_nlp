{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a25f737",
   "metadata": {},
   "source": [
    "# 9.2\tEin Modell mit zwei Eingängen aufbauen und anlernen\n",
    "(Rechtschreibkorrektur mit falsch geschriebenen Wort + Kontext (Wort vor- und nach fehlerhaftem Wort)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea35f2b",
   "metadata": {},
   "source": [
    "### 01 - Importe und Vorverarbeitungsklassen laden\n",
    "Die Klasse *SpellingMistake* liegt im aktuellen Ordner. Mit ihr lassen sich für ein übergebenes Wort Rechtschreibfehler produzieren.<br>\n",
    "Das Objekt *seq_encoder* wurde in Kapitel 6 rekurrente Netze beschrieben und angelernt. An dieser Stelle wird nur noch ein fertiges Objekt zur Verwendung geladen<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a625dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sequence_encoder.SequenceEncoder at 0x1e43a8ca808>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sequence_encoder import SequenceEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from spelling_mistake import SpellingMistake\n",
    "\n",
    "spel_mistake = SpellingMistake()\n",
    "seq_encoder = joblib.load('seq_encoder.pkl')\n",
    "seq_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c0206",
   "metadata": {},
   "source": [
    "#### Daten laden\n",
    "Die Daten sind bereits vorbereitet worden. Dabei wurden aus realen Sätzen jeweils drei Wortpaare \n",
    "(mittleres Wort, vorheriges Wort (pre) und nachfolgendes Wort (post) herausgeschnitten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79dd571a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pre</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eine</td>\n",
       "      <td>sie</td>\n",
       "      <td>notlüge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zu</td>\n",
       "      <td>00:04</td>\n",
       "      <td>sehen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ist</td>\n",
       "      <td>luis</td>\n",
       "      <td>kerngesund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eine</td>\n",
       "      <td>trägt</td>\n",
       "      <td>moderatorin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vor</td>\n",
       "      <td>moderatorin</td>\n",
       "      <td>&lt;noword&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word          pre         post\n",
       "0  eine          sie      notlüge\n",
       "1    zu        00:04        sehen\n",
       "2   ist         luis   kerngesund\n",
       "3  eine        trägt  moderatorin\n",
       "4   vor  moderatorin     <noword>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import join\n",
    "path = r'..\\Data'\n",
    "\n",
    "df_test = pd.read_csv(join(path, 'test_sentences_cln.csv'))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4a7408",
   "metadata": {},
   "source": [
    "#### Tokenizer anlernen (Wörter im Kontext werden als Integers dargestellt - für Word Embedding)\n",
    "\n",
    "**Wichtiger Hinweis:** Da die Trainingsdaten zu groß für github sind, werden an dieser Stelle nur die Testdaten verwendet. Daher entstehen Abweichungen von den Ergebnissen des Buches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73923720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sie notlüge', '00:04 sehen', 'luis kerngesund', 'trägt moderatorin', 'moderatorin <noword>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tokenizer_pos.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "x2_test = df_test[['pre', 'post']].values\n",
    "x2_test = [ el[0] + ' ' + el[1] for el in x2_test]\n",
    "print(x2_test[:5])\n",
    "tok.fit_on_texts(x2_test)\n",
    "joblib.dump(tok, 'tokenizer_pos.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee1fb4c",
   "metadata": {},
   "source": [
    "#### Hiweis: Fehlende Wörter (zum Beispiel am Anfagn eines Satzes) werden mit *\\<noword\\>* kodiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27a4866b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 558], [1, 558], [558, 1]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.texts_to_sequences(['das haus', '<noword> haus', 'haus <noword>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e032358",
   "metadata": {},
   "source": [
    "### 02 - Daten vorbereiten\n",
    "- Zunächst eine Generator-Funktion erzeugen\n",
    "- Aufruf der Generator-Funktion mit Beispieldaten (Die Daten (Sätze) liegen im Ordner *Data* unter *train_sentences_cln.csv* bzw. *test_sentences_cln.csv*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d68ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_position_feeder(filepath: str, \n",
    "                         seq_encoder,\n",
    "                         tokenizer,\n",
    "                         spel_mistake,\n",
    "                         batch_size=1, epochs=1):\n",
    "    for i in range(epochs):\n",
    "        gen = pd.read_csv(filepath, chunksize=batch_size)\n",
    "        for df in gen:\n",
    "            y = df.iloc[:, 0].values\n",
    "            x1 = spel_mistake.gen_misspelling(y)\n",
    "            x1 = seq_encoder.gen_one_hot_data(x1)\n",
    "            x2 = df.iloc[:, 1:].values\n",
    "            x2 = [ str(el[0]) + ' ' + str(el[1]) for el in x2]\n",
    "            x2 = tok.texts_to_sequences(x2)\n",
    "            x2 = pad_sequences(x2, maxlen=2, padding='post', truncating='post')\n",
    "            y = np.array([seq_encoder.word_to_int(y_) for y_ in y])\n",
    "            yield [x1, x2], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12625217",
   "metadata": {},
   "source": [
    "#### Beispieldaten (erste 10 Zeilen) ansehen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aa8a111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eine,sie,notlüge\n",
      "zu,00:04,sehen\n",
      "ist,luis,kerngesund\n",
      "eine,trägt,moderatorin\n",
      "vor,moderatorin,<noword>\n",
      "dem,auf,weg\n",
      "spiel,das,gewinnt\n",
      "menschen,mit,gesprochen\n",
      "die,bond,meiste\n",
      "blick,0:0,special\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "path = r'..\\Data'\n",
    "\n",
    "count = 0\n",
    "with open(join(path, join(path, 'test_sentences_cln.csv')), 'r', encoding='utf-8') as doc:\n",
    "        next(doc)\n",
    "        for el in doc:\n",
    "            print(el, end='')\n",
    "            count += 1\n",
    "            if count==10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afd2dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "path = r'..\\Data'\n",
    "\n",
    "gen = word_position_feeder( join(path, 'test_sentences_cln.csv'), \n",
    "                     seq_encoder, tok, spel_mistake, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79046dcf",
   "metadata": {},
   "source": [
    "#### Test der Generator-Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f712232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([array([[[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]), array([[   17, 35796]])], array([117]))\n"
     ]
    }
   ],
   "source": [
    "for el in gen:\n",
    "    print(el)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39e6e1",
   "metadata": {},
   "source": [
    "### 03 - Lernmodell aufsetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a07eb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_in (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "seq_in (InputLayer)             [(None, 15, 32)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "l2_embedding (Embedding)        (None, 2, 10)        918930      words_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "l1_cnn (Conv1D)                 (None, 13, 32)       3104        seq_in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "l2_flatten (Flatten)            (None, 20)           0           l2_embedding[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "l1_rnn_fwd (GRU)                (None, 32)           6336        l1_cnn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "l1_rnn_bwd (GRU)                (None, 32)           6336        l1_cnn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "l2_dense (Dense)                (None, 20)           420         l2_flatten[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "l1_l2_conc (Concatenate)        (None, 84)           0           l1_rnn_fwd[0][0]                 \n",
      "                                                                 l1_rnn_bwd[0][0]                 \n",
      "                                                                 l2_dense[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 500)          42500       l1_l2_conc[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 977,626\n",
      "Trainable params: 977,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, GRU, Flatten, Dense, Conv1D, Concatenate, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_1 = Input(shape=[15, 32], name='seq_in')\n",
    "input_2 = Input(shape=[2,], name='words_in')\n",
    "\n",
    "line_1 = Conv1D( filters=32, \n",
    "                kernel_size=3,\n",
    "                activation='relu',\n",
    "                name='l1_cnn')(input_1)\n",
    "line_1a = GRU(units=32, name='l1_rnn_fwd')(line_1)\n",
    "line_1b = GRU(units=32, go_backwards=True,\n",
    "              name='l1_rnn_bwd')(line_1)\n",
    "\n",
    "\n",
    "line_2 = Embedding(input_dim=len(tok.word_index)+1, \n",
    "                  output_dim=10,\n",
    "                  name='l2_embedding')(input_2)\n",
    "line_2 = Flatten(name='l2_flatten')(line_2)\n",
    "line_2 = Dense(units=20, activation='tanh', name='l2_dense')(line_2)\n",
    "\n",
    "out = Concatenate(name='l1_l2_conc')([line_1a, line_1b, line_2])\n",
    "out = Dense(units=500, activation='softmax', name='out')(out)\n",
    "\n",
    "model = Model([input_1, input_2], out)\n",
    "\n",
    "model.compile(  loss='sparse_categorical_crossentropy', \n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af8478",
   "metadata": {},
   "source": [
    "### 04 - Modell anlernen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16d279",
   "metadata": {},
   "source": [
    "#### Testgeneratoren mit einer Epoche aufrufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c53ed4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "path = r'..\\Data'\n",
    "\n",
    "test_gen = word_position_feeder( join(path, 'test_sentences_cln.csv'), \n",
    "                     seq_encoder, tok, spel_mistake, batch_size=128, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0651d9",
   "metadata": {},
   "source": [
    "#### Steps per Epoch für Trainings- und Testdaten herausfinden (unter Umständen überspringen - dauert eine Weile!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08182cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test steps per epoch 3815\n"
     ]
    }
   ],
   "source": [
    "count_test = 0\n",
    "for el in test_gen:\n",
    "        count_test+=1\n",
    "print('Test steps per epoch', count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e1367",
   "metadata": {},
   "source": [
    "#### Anlernprozess starten (dauert sehr lange!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "102defb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3815/3815 [==============================] - 95s 25ms/step - loss: 1.3025 - accuracy: 0.7248\n",
      "Epoch 2/100\n",
      "3815/3815 [==============================] - 98s 26ms/step - loss: 0.2811 - accuracy: 0.9232\n",
      "Epoch 3/100\n",
      "3815/3815 [==============================] - 98s 26ms/step - loss: 0.1863 - accuracy: 0.9438\n",
      "Epoch 4/100\n",
      "3815/3815 [==============================] - 98s 26ms/step - loss: 0.1481 - accuracy: 0.9528\n",
      "Epoch 5/100\n",
      "2503/3815 [==================>...........] - ETA: 33s - loss: 0.1272 - accuracy: 0.9586"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from os.path import join\n",
    "path = r'..\\Data'\n",
    "\n",
    "### Testgenerator noch einmal neu aufsetzen (mit 100 Epochen Voreinstellung)\n",
    "### Hinweis: Wie oben beschrieben, können die Trainingsdaten aus Ressourcengründen nicht auf GitHub \n",
    "### hochgeladen werden. Daher werden die Testdaten zum Anlernen verwendet!\n",
    "\n",
    "test_gen = word_position_feeder( join(path, 'test_sentences_cln.csv'), \n",
    "                     seq_encoder, tok, spel_mistake, batch_size=128, epochs=100)\n",
    "\n",
    "stopping = EarlyStopping( monitor='loss', \n",
    "                          patience=1,\n",
    "                          restore_best_weights=False)\n",
    "checkpoint = ModelCheckpoint( filepath='spell_correction_context.h5',\n",
    "                              monitor='loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "history = model.fit( test_gen, steps_per_epoch=3815, epochs=100, \n",
    "                     callbacks=[stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564816c5",
   "metadata": {},
   "source": [
    "#### Anglernetes Modell laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('spell_correction_context.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26086f",
   "metadata": {},
   "source": [
    "### 05 - Modell zur Korrektur von Wörtern einsetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb604d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_correct(misspelled:str, pre_post:str):\n",
    "    word = seq_encoder.gen_one_hot_data([misspelled])\n",
    "    pre_post = tok.texts_to_sequences([pre_post])\n",
    "    pre_post = pad_sequences( pre_post, maxlen=2, \n",
    "                              padding='post', \n",
    "                              truncating='post')\n",
    "    print(pre_post)\n",
    "    word_idx = model.predict([word, pre_post])\n",
    "    word_idx = np.argmax(word_idx[0])\n",
    "    correct_word = seq_encoder.int_to_word(word_idx)\n",
    "    return correct_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e0a120",
   "metadata": {},
   "source": [
    "#### Schätzungen\n",
    "**Hinweis:** Fehlende Wörter vorne müssen als \\<noword\\> codiert werden<br>\n",
    "Zum Beispiel der Satz \"Daas Haus steht auf dem Berg\" --> pre_post='\\<noword\\> haus', word='daas' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bea6eb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3732   13]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'liegt'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = 'schnee lieeeg auf dem berg'\n",
    "word = 'lieeg'\n",
    "pre_post = 'schnee auf'\n",
    "predict_correct(word, pre_post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
