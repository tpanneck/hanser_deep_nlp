{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a171f66d",
   "metadata": {},
   "source": [
    "## 11.3.5\tFine Tuning vortrainierter Netze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472f852",
   "metadata": {},
   "source": [
    "### 01 - Das vortrainierte Modell mit spezifischem Kopf laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d8f93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ( AutoTokenizer,\n",
    "                           TFAutoModelForSequenceClassification)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained( \n",
    "                 'bert-base-cased', num_labels=2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33ef3a2",
   "metadata": {},
   "source": [
    "#### Modell inspzieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b09bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d27f08",
   "metadata": {},
   "source": [
    "### 02 - Eine Durchleitung organisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55b7bb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.19170247, -0.01770693]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"It's impossible to watch this movie for longer than 5 minutes\"\n",
    "inputs = tokenizer(text, return_tensors='tf')\n",
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ed9a5",
   "metadata": {},
   "source": [
    "#### Ausgabe mit Softmax aktivieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a6b93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.45661053, 0.5433895 ]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "predictions = tf.math.softmax(output['logits'], axis=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47b6a92",
   "metadata": {},
   "source": [
    "### 03 - Teile des Netzes auf nicht-trainierbar einstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c8856",
   "metadata": {},
   "source": [
    "#### Den kompletten Encoder auf nicht-trainierbar einstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25756f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 108,310,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.get_layer(index=0).trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c7ce5f",
   "metadata": {},
   "source": [
    "#### Die Layer des Encoders checken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d120c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4D5D588>\n",
      "1 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4D41EC8>\n",
      "2 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4DAC408>\n",
      "3 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4DBF988>\n",
      "4 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4DD7EC8>\n",
      "5 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4DF03C8>\n",
      "6 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4E06A08>\n",
      "7 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4E200C8>\n",
      "8 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4E36708>\n",
      "9 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4E4BC88>\n",
      "10 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4E653C8>\n",
      "11 <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000155F4E7AA08>\n"
     ]
    }
   ],
   "source": [
    "main_model = model.get_layer(index=0)\n",
    "for idx, layer in enumerate(main_model.encoder.layer):\n",
    "   print(idx, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f032b",
   "metadata": {},
   "source": [
    "#### Die letzten drei Schichten auf *not trainable* setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e36f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 44,520,962\n",
      "Non-trainable params: 63,790,848\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "main_model.trainable = True\n",
    "for idx, layer in enumerate(main_model.encoder.layer):\n",
    "   if idx in range(0, 9):\n",
    "      layer.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53fe31",
   "metadata": {},
   "source": [
    "### 4 - Das Modell nachtrainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78122a5d",
   "metadata": {},
   "source": [
    "#### IMDB-Review-Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01bc9417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                              review sentiment\n",
       " 0  One of the other reviewers has mentioned that ...  positive\n",
       " 1  A wonderful little production. <br /><br />The...  positive\n",
       " 2  I thought this was a wonderful way to spend ti...  positive\n",
       " 3  Basically there's a family where a little boy ...  negative\n",
       " 4  Petter Mattei's \"Love in the Time of Money\" is...  positive,\n",
       " (45000,),\n",
       " (45000,),\n",
       " (5000,),\n",
       " (5000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "path = r'..\\Data'\n",
    "file = 'IMDB dataset.csv'\n",
    "\n",
    "df = pd.read_csv(join(path, file))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['review'].values\n",
    "y = df['sentiment'].map(lambda x: 1 if x=='positive' else 0).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=11)\n",
    "df.head(), X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b755c3f",
   "metadata": {},
   "source": [
    "#### Die x-Daten tokenisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cfedf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([45000, 50]), TensorShape([5000, 50]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tok = dict(tokenizer(X_train.tolist(), padding=\"max_length\", \n",
    "                        truncation=True, max_length=50, return_tensors='tf'\n",
    "                        ))\n",
    "X_test_tok = dict(tokenizer(X_test.tolist(), padding=\"max_length\", \n",
    "                       truncation=True,  max_length=50, return_tensors='tf'\n",
    "                       ))\n",
    "X_train_tok['input_ids'].shape, X_test_tok['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636e5b4",
   "metadata": {},
   "source": [
    "#### Das Modell kompilieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a63e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=5e-5),\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad05b1b",
   "metadata": {},
   "source": [
    "#### Den kompletten Encoder wider auf not trainable setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008ab61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 108,310,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.get_layer(index=0).trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facaf84a",
   "metadata": {},
   "source": [
    "#### Den Anlernprozess starten\n",
    "**Hinweis:** Trainingsprozess ist hier nur angedeutet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c2f4c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x155e998c198>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x155e998c198>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "  96/2813 [>.............................] - ETA: 3:45:32 - loss: 0.6287 - accuracy: 0.6191"
     ]
    }
   ],
   "source": [
    "model.fit( X_train_tok, \n",
    "          y_train, \n",
    "           epochs=1, \n",
    "           batch_size=16, \n",
    "           validation_data=(X_test_tok, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12898c1",
   "metadata": {},
   "source": [
    "#### Angelerntes Modell abspeichern bzw. laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db3a8f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert_sentiment_trained were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at bert_sentiment_trained.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "### Speichern\n",
    "model.save_pretrained('bert_sentiment_trained')\n",
    "\n",
    "#### Laden\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "                                         'bert_sentiment_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83123828",
   "metadata": {},
   "source": [
    "#### Schätungen durcführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "621f87b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.72925985, 0.27074018]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "text = \"It's impossible to watch this movie for longer than 5 minutes\"\n",
    "inputs = tokenizer(text, return_tensors='tf')\n",
    "output = model(**inputs)\n",
    "predictions = tf.math.softmax(output['logits'], axis=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e283be5",
   "metadata": {},
   "source": [
    "Interpretation: Class 0 (negative): 72,9%, Class 1 (positive): 27,1%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
