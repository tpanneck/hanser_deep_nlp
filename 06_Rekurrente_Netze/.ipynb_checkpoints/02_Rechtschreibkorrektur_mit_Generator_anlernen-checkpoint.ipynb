{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cc048ec",
   "metadata": {},
   "source": [
    "# 6.4.4 Rechtschreibkorrektur mit einem Generator anlernen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1dde6a",
   "metadata": {},
   "source": [
    "## 01 - Fertige Spelling-Daten laden \n",
    "Produktion der Spelling-Daten vgl. vorheriges Jupyter Notebook im gleichen Ordner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96ac3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12737, 2),\n",
       " (3184, 2),\n",
       "           misspelling            word\n",
       " 11595          elwern          eltern\n",
       " 11628       gemeinsan       gemeinsam\n",
       " 14713  beispielsweiße  beispielsweise\n",
       " 15648        promramm        programm\n",
       " 8182           yeinen          keinen)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from math import ceil\n",
    "\n",
    "path = r'..\\Data'\n",
    "\n",
    "df_spelling = pd.read_csv(  join(path, 'spelling_data.csv'),\n",
    "                             na_filter=False)\n",
    "\n",
    "### Einteilung in Train/Testpartitionen \n",
    "df_spelling.head()\n",
    "df_train = df_spelling.sample(frac=.8)\n",
    "df_test = df_spelling.drop(index=df_train.index)\n",
    "\n",
    "### Abspeichern von Trainings- und Testdaten als CSV-Datei (wird später in Generator gebraucht)\n",
    "df_train.to_csv(join(path, 'train_spelling.csv'), index=None)\n",
    "df_test.to_csv(join(path, 'test_spelling.csv'), index=None)\n",
    "\n",
    "df_train.shape, df_test.shape, df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3cb284",
   "metadata": {},
   "source": [
    "## 02 - Generator zur Anlieferung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f6527",
   "metadata": {},
   "source": [
    "#### Zunächst: Laden des Objects deq_encoder der Klasse *SequenceEncoder*. \n",
    "Dazu verwenden wir ein bereits angelerntes Objekt der Klasse *SequenceEncoder*; \n",
    "vgl. vorheriges Jupyter Notebook im gleichen Ordner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a81003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sequence_encoder.SequenceEncoder at 0x161a3615e48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sequence_encoder import SequenceEncoder\n",
    "\n",
    "seq_encoder = joblib.load('seq_encoder.pkl')\n",
    "seq_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52125da5",
   "metadata": {},
   "source": [
    "#### Generator-Funktion erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c025be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_spelling_data( filepath: str, \n",
    "                             batch_size: int, \n",
    "                             epochs: int,\n",
    "                             seq_encoder: SequenceEncoder):\n",
    "    for epoch in range(epochs):\n",
    "        gen = pd.read_csv(filepath, chunksize=batch_size)\n",
    "        for df in gen:\n",
    "            X, y = df['misspelling'].values, df['word'].values\n",
    "            X = seq_encoder.gen_one_hot_data(X)\n",
    "            y = np.array([ seq_encoder.word_to_int(y_) for y_ in y])\n",
    "            yield X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f263f",
   "metadata": {},
   "source": [
    "#### Generator-Funktion aufrufen und testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4241a402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]),\n",
       " array([95]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = generator_spelling_data(join(path, 'spelling_data.csv'), \n",
    "                        batch_size=1, epochs=1, \n",
    "                        seq_encoder=seq_encoder)\n",
    "\n",
    "### Erstes Datenbatch ansehen\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc3f3f8",
   "metadata": {},
   "source": [
    "## 03 - Schätzmodell zusammenstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6ed5ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 64)                12672     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               32500     \n",
      "=================================================================\n",
      "Total params: 45,172\n",
      "Trainable params: 45,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, \n",
    "                                    GRU, Bidirectional)\n",
    "\n",
    "seq_length = seq_encoder.max_word_length # =15\n",
    "num_chars = len(seq_encoder.charset) # =32\n",
    "num_words = len(seq_encoder.word_idx) # =500\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(units=num_chars),\n",
    "              input_shape=(seq_length, num_chars)))\n",
    "model.add(Dense(units=num_words, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(  loss='sparse_categorical_crossentropy', \n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8914ce4",
   "metadata": {},
   "source": [
    "## 04 - Modell anlernen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf0026",
   "metadata": {},
   "source": [
    "#### Bestimmung der Steps per Epoch für Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8af5fac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_train = ceil(df_train.shape[0] / 32)\n",
    "steps_test = ceil(df_test.shape[0] / 32)\n",
    "steps_train, steps_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215e738",
   "metadata": {},
   "source": [
    "#### Callbacks zusammenstellen, Generator-Funktionen aufrufen und Modell anlernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f394c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "399/399 [==============================] - 5s 13ms/step - loss: 5.4985 - accuracy: 0.0301 - val_loss: 4.7945 - val_accuracy: 0.0810\n",
      "Epoch 2/200\n",
      "399/399 [==============================] - 4s 11ms/step - loss: 4.0419 - accuracy: 0.2515 - val_loss: 3.3978 - val_accuracy: 0.3838\n",
      "Epoch 3/200\n",
      "399/399 [==============================] - 4s 11ms/step - loss: 2.8195 - accuracy: 0.4974 - val_loss: 2.4395 - val_accuracy: 0.5609\n",
      "Epoch 4/200\n",
      "399/399 [==============================] - 4s 11ms/step - loss: 2.0607 - accuracy: 0.6226 - val_loss: 1.8841 - val_accuracy: 0.6404\n",
      "Epoch 5/200\n",
      "399/399 [==============================] - 4s 10ms/step - loss: 1.6081 - accuracy: 0.6938 - val_loss: 1.5438 - val_accuracy: 0.6891\n",
      "Epoch 6/200\n",
      "399/399 [==============================] - 4s 11ms/step - loss: 1.3136 - accuracy: 0.7430 - val_loss: 1.3200 - val_accuracy: 0.7261\n",
      "Epoch 7/200\n",
      "399/399 [==============================] - 4s 11ms/step - loss: 1.1051 - accuracy: 0.7773 - val_loss: 1.1579 - val_accuracy: 0.7541\n",
      "Epoch 8/200\n",
      "399/399 [==============================] - 4s 11ms/step - loss: 0.9496 - accuracy: 0.8064 - val_loss: 1.0347 - val_accuracy: 0.7789\n",
      "Epoch 9/200\n",
      "399/399 [==============================] - 4s 10ms/step - loss: 0.8294 - accuracy: 0.8282 - val_loss: 0.9346 - val_accuracy: 0.7955\n",
      "Epoch 32/200\n",
      "399/399 [==============================] - 5s 13ms/step - loss: 0.1363 - accuracy: 0.9769 - val_loss: 0.4598 - val_accuracy: 0.8763\n",
      "Epoch 33/200\n",
      "399/399 [==============================] - 5s 12ms/step - loss: 0.1295 - accuracy: 0.9785 - val_loss: 0.4617 - val_accuracy: 0.8759\n",
      "Epoch 34/200\n",
      "399/399 [==============================] - 5s 12ms/step - loss: 0.1231 - accuracy: 0.9791 - val_loss: 0.4631 - val_accuracy: 0.8769\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "stopping = EarlyStopping( monitor='val_loss', \n",
    "                          patience=3,\n",
    "                          restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint( filepath='model_auto_correction_bid.h5',\n",
    "                              monitor='val_loss',\n",
    "                              save_best_only=True)\n",
    "\n",
    "gen_train = generator_spelling_data(join(path, 'train_spelling.csv'), \n",
    "                        batch_size=32, epochs=200, \n",
    "                        seq_encoder=seq_encoder)\n",
    "gen_test = generator_spelling_data(join(path, 'test_spelling.csv'), \n",
    "                        batch_size=32, epochs=200, \n",
    "                        seq_encoder=seq_encoder)\n",
    "\n",
    "\n",
    "history = model.fit(gen_train, epochs=200,\n",
    "            steps_per_epoch=399,\n",
    "            callbacks=[stopping, checkpoint],\n",
    "            validation_data=gen_test,\n",
    "            validation_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a9d40",
   "metadata": {},
   "source": [
    "## 05 - Schätzungen durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08b12ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allein\n",
      "frage\n",
      "beispiel\n"
     ]
    }
   ],
   "source": [
    "test_example = np.array(['alllein', 'frahe', 'beistiel'])\n",
    "test_example = seq_encoder.gen_one_hot_data(test_example)\n",
    "\n",
    "pred_word_prob = model.predict(test_example)\n",
    "pred_word_idx = np.argmax(pred_word_prob, axis=1)\n",
    "\n",
    "### 3) Daten decodieren\n",
    "for idx in pred_word_idx:\n",
    "    print(seq_encoder.int_to_word(idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
